{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PREPROCESAMIENTO CON SPACY"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tokenización"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "nlp = spacy.load('es_core_news_sm')\n",
    "\n",
    "# text = \"\"\" La búsqueda de información en la web en los últimos años ha sido de vital importancia en el ámbito de las investigaciones. Debido al crecimiento vertiginoso de la información disponible en Internet, la cantidad de resultados obtenidos es muy amplia y muchas veces estos resultados no dicen nada significativo, por tal motivo, se observa la necesidad de reducir esa brecha y brindar resultados significativos y de importancia para el usuario. Muchos de los motores de búsqueda actuales realizan una búsqueda que se basa en la sintaxis de la información que se desea consultar; lo que hacen es encontrar coincidencias, ilustrando una lista de páginas web que pueden contener la respuesta, pero la mayoría de veces el usuario debe determinar si la información presentada es la correcta, convirtiéndose en una tarea bastante compleja dado la cantidad de resultados obtenidos. Los buscadores semánticos en cambio, encuentran resultados en función del contexto, información más exacta acerca de lo que se busca, ofreciendo una cantidad de resultados más sesgada, facilitando la labor de filtrar los resultados por parte del usuario. En el presente proyecto de trabajo de grado se plantea construir un motor de búsqueda inteligente, haciendo uso de la semántica mediante el gestor de base de datos SPARQL y del lenguaje RDF con el manejo de ontologías, que permita recuperar y encontrar la información solicitada de los documentos de investigación que se encuentran digitalizados en el Sistema de Investigaciones de la Universidad de Nariño. El proyecto será desarrollado por estudiantes investigadores del grupo de investigación GRIAS del programa de Ingeniería de Sistemas, de la facultad de Ingeniería de la Universidad de Nariño. De esta manera la investigación propende generar más investigación dentro de la Universidad de Nariño. Ésta es una herramienta orientada a la comunidad investigadora, que incorpora tecnologías, conocimientos y herramientas innovadoras como son: la web semántica, las ontologías, los motores de búsqueda, SPARQL y el lenguaje RDF, fundamentándose en el esquema de las bases de datos y la IA (Inteligencia Artificial); dos potentes ámbitos que en la actualidad son la raíz de muchos frutos obtenidos en la tecnología, que lo que hacen es facilitar la vida a las personas, fomentar la competitividad, motivar al cambio y generar conocimiento que enriquezca la vida informática y computacional. \"\"\"\n",
    "# text += \"\"\"MOTOR DE BÚSQUEDA INTELIGENTE DE INFORMES DE INVESTIGACIÓN BASADO EN RECURSOS SEMÁNTICOS PARA EL SISTEMA DE INVESTIGACIONES DE LA UNIVERSIDAD DE NARIÑO\"\"\"\n",
    "# text += \"\"\"Web Semántica,SPARQL, RDF, Ontologia,  Motor de Búsqueda, Documentos Digitales\"\"\"\n",
    "# text += \"\"\" FELIPE CUJAR ROSERO, Ingeniería de Sistemas, DAVID SANTIAGO PINCHAO ORTIZ, Silvio Ricardo, GRIAS \"\"\"\n",
    "# text += \"\"\" Herramientas y sistemas de gestión de conocimiento y recuperación de información \"\"\"\n",
    "\n",
    "###\n",
    "##PRUEBA\n",
    "text2 = \"\"\" Ingeniería de Sistemas, DAVID SANTIAGO PINCHAO ORTIZ, Silvio Ricardo Timaran Pereira, GRIAS \"\"\"\n",
    "text2 += \"\"\" Herramientas y sistemas de gestión de conocimiento y recuperación de informacion, humano \"\"\"\n",
    "document = nlp(text2) # Crea un objeto de spacy tipo nlp\n",
    "###\n",
    "\n",
    "# document = nlp(text) # Crea un objeto de spacy tipo nlp\n",
    "tokens = [t.orth_ for t in document] # Crea una lista con las palabras del texto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[' ',\n",
       " 'FELIPE',\n",
       " 'CUJAR',\n",
       " 'ROSERO',\n",
       " ',',\n",
       " 'Ingeniería',\n",
       " 'de',\n",
       " 'Sistemas',\n",
       " ',',\n",
       " 'DAVID',\n",
       " 'SANTIAGO',\n",
       " 'PINCHAO',\n",
       " 'ORTIZ',\n",
       " ',',\n",
       " 'Silvio',\n",
       " 'Ricardo',\n",
       " 'Timaran',\n",
       " 'Pereira',\n",
       " ',',\n",
       " 'GRIAS',\n",
       " ' ',\n",
       " 'Herramientas',\n",
       " 'y',\n",
       " 'sistemas',\n",
       " 'de',\n",
       " 'gestión',\n",
       " 'de',\n",
       " 'conocimiento',\n",
       " 'y',\n",
       " 'recuperación',\n",
       " 'de',\n",
       " 'informacion',\n",
       " ',',\n",
       " 'humano']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tokenización y Limpieza de signos de puntuación y stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_words = [t.orth_ for t in document if not t.is_punct | t.is_stop]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[' ',\n",
       " 'FELIPE',\n",
       " 'CUJAR',\n",
       " 'ROSERO',\n",
       " 'Ingeniería',\n",
       " 'Sistemas',\n",
       " 'DAVID',\n",
       " 'SANTIAGO',\n",
       " 'PINCHAO',\n",
       " 'ORTIZ',\n",
       " 'Silvio',\n",
       " 'Ricardo',\n",
       " 'Timaran',\n",
       " 'Pereira',\n",
       " 'GRIAS',\n",
       " ' ',\n",
       " 'Herramientas',\n",
       " 'y',\n",
       " 'sistemas',\n",
       " 'gestión',\n",
       " 'conocimiento',\n",
       " 'y',\n",
       " 'recuperación',\n",
       " 'informacion',\n",
       " 'humano']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalización"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalized_words = [t.lower() for t in clean_words if len(t) > 2 and t.isalpha()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['felipe',\n",
       " 'cujar',\n",
       " 'rosero',\n",
       " 'ingeniería',\n",
       " 'sistemas',\n",
       " 'david',\n",
       " 'santiago',\n",
       " 'pinchao',\n",
       " 'ortiz',\n",
       " 'silvio',\n",
       " 'ricardo',\n",
       " 'timaran',\n",
       " 'pereira',\n",
       " 'grias',\n",
       " 'herramientas',\n",
       " 'sistemas',\n",
       " 'gestión',\n",
       " 'conocimiento',\n",
       " 'recuperación',\n",
       " 'informacion',\n",
       " 'humano']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "normalized_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(normalized_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convertir a objeto nlp la lista normalizada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_document = nlp(str(normalized_words)) # Crea un objeto de spacy tipo nlp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "spacy.tokens.doc.Doc"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(new_document)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lematización"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmas = [t.lemma_.lower() for t in new_document if not t.is_punct] ## en esta misma línea se ha eliminado puntuación"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['felipe',\n",
       " 'cujar',\n",
       " 'rosero',\n",
       " 'ingeniería',\n",
       " 'sistema',\n",
       " 'david',\n",
       " 'santiago',\n",
       " 'pinchao',\n",
       " 'ortiz',\n",
       " 'silvio',\n",
       " 'ricardo',\n",
       " 'timar',\n",
       " 'pereira',\n",
       " 'grias',\n",
       " 'herramienta',\n",
       " 'sistema',\n",
       " 'gestión',\n",
       " 'conocimiento',\n",
       " 'recuperación',\n",
       " 'informacion',\n",
       " 'humanar']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lemmas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lematización con variaciones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmas_without_verbs = [t.lemma_.lower() for t in new_document if t.pos_ != 'VERB' and not t.is_punct]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['felipe',\n",
       " 'rosero',\n",
       " 'sistema',\n",
       " 'david',\n",
       " 'santiago',\n",
       " 'pinchao',\n",
       " 'ortiz',\n",
       " 'silvio',\n",
       " 'ricardo',\n",
       " 'pereira',\n",
       " 'grias',\n",
       " 'herramienta',\n",
       " 'sistema',\n",
       " 'gestión',\n",
       " 'conocimiento',\n",
       " 'recuperación',\n",
       " 'informacion',\n",
       " 'humanar']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lemmas_without_verbs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmas_with_verbs = [t.lemma_.lower() for t in new_document if t.pos_ == 'VERB' and not t.is_punct]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['cujar', 'ingeniería', 'timar']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lemmas_with_verbs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmas_without_prons = [t.lemma_.lower() for t in new_document if t.pos_ != 'PRON' and not t.is_punct]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['felipe',\n",
       " 'cujar',\n",
       " 'rosero',\n",
       " 'ingeniería',\n",
       " 'sistema',\n",
       " 'david',\n",
       " 'santiago',\n",
       " 'pinchao',\n",
       " 'ortiz',\n",
       " 'silvio',\n",
       " 'ricardo',\n",
       " 'timar',\n",
       " 'pereira',\n",
       " 'grias',\n",
       " 'herramienta',\n",
       " 'sistema',\n",
       " 'gestión',\n",
       " 'conocimiento',\n",
       " 'recuperación',\n",
       " 'informacion',\n",
       " 'humanar']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lemmas_without_prons"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ALL EXECUTION IN ONE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "nlp = spacy.load('es_core_news_sm')\n",
    "\n",
    "text2 = \"\"\" [ 太陽 la de para pos contra el ellos tu yo Ingeniería de Sistemas, DAVID SANTIAGO PINCHAO ORTIZ, Silvio Ricardo Timaran Pereira, GRIAS. \"\"\"\n",
    "text2 += \"\"\" Conocerse Herramientas y timar sistemas de gestión de conocimiento y recuperación de informacion, humano humanos humanaras Pasto\"\"\"\n",
    "\n",
    "document = nlp(text2) # Crea un objeto de spacy tipo nlp\n",
    "\n",
    "tokens = [t.orth_ for t in document] # Crea una lista con las palabras del texto\n",
    "\n",
    "clean_words = [t.orth_ for t in document if not t.is_punct | t.is_stop]\n",
    "\n",
    "normalized_words = [t.lower() for t in clean_words if len(t) > 2 and t.isalpha()]\n",
    "\n",
    "new_document = nlp(str(normalized_words)) # Crea un objeto de spacy tipo nlp\n",
    "\n",
    "lemmas = [t.lemma_.lower() for t in new_document if not t.is_punct] ## en esta misma línea se ha eliminado puntuación\n",
    "\n",
    "lemmas_without_verbs = [t.lemma_.lower() for t in new_document if t.pos_ != 'VERB' and not t.is_punct]\n",
    "\n",
    "lemmas_with_verbs = [t.lemma_.lower() for t in new_document if t.pos_ == 'VERB' and not t.is_punct]\n",
    "\n",
    "lemmas_without_prons = [t.lemma_.lower() for t in new_document if t.pos_ != 'PRON' and not t.is_punct]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['felipe',\n",
       " 'cujar',\n",
       " 'rosero',\n",
       " 'pos',\n",
       " 'ingeniería',\n",
       " 'sistema',\n",
       " 'david',\n",
       " 'santiago',\n",
       " 'pinchao',\n",
       " 'ortiz',\n",
       " 'silvio',\n",
       " 'ricardo',\n",
       " 'timar',\n",
       " 'pereira',\n",
       " 'grias',\n",
       " 'conocerse',\n",
       " 'herramienta',\n",
       " 'timar',\n",
       " 'sistema',\n",
       " 'gestión',\n",
       " 'conocimiento',\n",
       " 'recuperación',\n",
       " 'informacion',\n",
       " 'humanar',\n",
       " 'humano',\n",
       " 'humanar',\n",
       " 'pastar']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lemmas"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
