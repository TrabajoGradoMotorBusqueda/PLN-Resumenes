{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Limpieza y Tokenizacion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Cargamos librerias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "sp = spacy.load('es_core_news_sm')\n",
    "stop_words = list(sp.Defaults.stop_words)\n",
    "from nltk.corpus import stopwords\n",
    "stopwords_español = stopwords.words('spanish')\n",
    "aditionalwords= [palabra for palabra in stopwords_español if palabra not in stop_words ]\n",
    "stop_words.extend(aditionalwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['de',\n",
       " 'la',\n",
       " 'que',\n",
       " 'el',\n",
       " 'en',\n",
       " 'y',\n",
       " 'a',\n",
       " 'los',\n",
       " 'del',\n",
       " 'se',\n",
       " 'las',\n",
       " 'por',\n",
       " 'un',\n",
       " 'para',\n",
       " 'con',\n",
       " 'no',\n",
       " 'una',\n",
       " 'su',\n",
       " 'al',\n",
       " 'lo',\n",
       " 'como',\n",
       " 'más',\n",
       " 'pero',\n",
       " 'sus',\n",
       " 'le',\n",
       " 'ya',\n",
       " 'o',\n",
       " 'este',\n",
       " 'sí',\n",
       " 'porque',\n",
       " 'esta',\n",
       " 'entre',\n",
       " 'cuando',\n",
       " 'muy',\n",
       " 'sin',\n",
       " 'sobre',\n",
       " 'también',\n",
       " 'me',\n",
       " 'hasta',\n",
       " 'hay',\n",
       " 'donde',\n",
       " 'quien',\n",
       " 'desde',\n",
       " 'todo',\n",
       " 'nos',\n",
       " 'durante',\n",
       " 'todos',\n",
       " 'uno',\n",
       " 'les',\n",
       " 'ni',\n",
       " 'contra',\n",
       " 'otros',\n",
       " 'ese',\n",
       " 'eso',\n",
       " 'ante',\n",
       " 'ellos',\n",
       " 'e',\n",
       " 'esto',\n",
       " 'mí',\n",
       " 'antes',\n",
       " 'algunos',\n",
       " 'qué',\n",
       " 'unos',\n",
       " 'yo',\n",
       " 'otro',\n",
       " 'otras',\n",
       " 'otra',\n",
       " 'él',\n",
       " 'tanto',\n",
       " 'esa',\n",
       " 'estos',\n",
       " 'mucho',\n",
       " 'quienes',\n",
       " 'nada',\n",
       " 'muchos',\n",
       " 'cual',\n",
       " 'poco',\n",
       " 'ella',\n",
       " 'estar',\n",
       " 'estas',\n",
       " 'algunas',\n",
       " 'algo',\n",
       " 'nosotros',\n",
       " 'mi',\n",
       " 'mis',\n",
       " 'tú',\n",
       " 'te',\n",
       " 'ti',\n",
       " 'tu',\n",
       " 'tus',\n",
       " 'ellas',\n",
       " 'nosotras',\n",
       " 'vosotros',\n",
       " 'vosotras',\n",
       " 'os',\n",
       " 'mío',\n",
       " 'mía',\n",
       " 'míos',\n",
       " 'mías',\n",
       " 'tuyo',\n",
       " 'tuya',\n",
       " 'tuyos',\n",
       " 'tuyas',\n",
       " 'suyo',\n",
       " 'suya',\n",
       " 'suyos',\n",
       " 'suyas',\n",
       " 'nuestro',\n",
       " 'nuestra',\n",
       " 'nuestros',\n",
       " 'nuestras',\n",
       " 'vuestro',\n",
       " 'vuestra',\n",
       " 'vuestros',\n",
       " 'vuestras',\n",
       " 'esos',\n",
       " 'esas',\n",
       " 'estoy',\n",
       " 'estás',\n",
       " 'está',\n",
       " 'estamos',\n",
       " 'estáis',\n",
       " 'están',\n",
       " 'esté',\n",
       " 'estés',\n",
       " 'estemos',\n",
       " 'estéis',\n",
       " 'estén',\n",
       " 'estaré',\n",
       " 'estarás',\n",
       " 'estará',\n",
       " 'estaremos',\n",
       " 'estaréis',\n",
       " 'estarán',\n",
       " 'estaría',\n",
       " 'estarías',\n",
       " 'estaríamos',\n",
       " 'estaríais',\n",
       " 'estarían',\n",
       " 'estaba',\n",
       " 'estabas',\n",
       " 'estábamos',\n",
       " 'estabais',\n",
       " 'estaban',\n",
       " 'estuve',\n",
       " 'estuviste',\n",
       " 'estuvo',\n",
       " 'estuvimos',\n",
       " 'estuvisteis',\n",
       " 'estuvieron',\n",
       " 'estuviera',\n",
       " 'estuvieras',\n",
       " 'estuviéramos',\n",
       " 'estuvierais',\n",
       " 'estuvieran',\n",
       " 'estuviese',\n",
       " 'estuvieses',\n",
       " 'estuviésemos',\n",
       " 'estuvieseis',\n",
       " 'estuviesen',\n",
       " 'estando',\n",
       " 'estado',\n",
       " 'estada',\n",
       " 'estados',\n",
       " 'estadas',\n",
       " 'estad',\n",
       " 'he',\n",
       " 'has',\n",
       " 'ha',\n",
       " 'hemos',\n",
       " 'habéis',\n",
       " 'han',\n",
       " 'haya',\n",
       " 'hayas',\n",
       " 'hayamos',\n",
       " 'hayáis',\n",
       " 'hayan',\n",
       " 'habré',\n",
       " 'habrás',\n",
       " 'habrá',\n",
       " 'habremos',\n",
       " 'habréis',\n",
       " 'habrán',\n",
       " 'habría',\n",
       " 'habrías',\n",
       " 'habríamos',\n",
       " 'habríais',\n",
       " 'habrían',\n",
       " 'había',\n",
       " 'habías',\n",
       " 'habíamos',\n",
       " 'habíais',\n",
       " 'habían',\n",
       " 'hube',\n",
       " 'hubiste',\n",
       " 'hubo',\n",
       " 'hubimos',\n",
       " 'hubisteis',\n",
       " 'hubieron',\n",
       " 'hubiera',\n",
       " 'hubieras',\n",
       " 'hubiéramos',\n",
       " 'hubierais',\n",
       " 'hubieran',\n",
       " 'hubiese',\n",
       " 'hubieses',\n",
       " 'hubiésemos',\n",
       " 'hubieseis',\n",
       " 'hubiesen',\n",
       " 'habiendo',\n",
       " 'habido',\n",
       " 'habida',\n",
       " 'habidos',\n",
       " 'habidas',\n",
       " 'soy',\n",
       " 'eres',\n",
       " 'es',\n",
       " 'somos',\n",
       " 'sois',\n",
       " 'son',\n",
       " 'sea',\n",
       " 'seas',\n",
       " 'seamos',\n",
       " 'seáis',\n",
       " 'sean',\n",
       " 'seré',\n",
       " 'serás',\n",
       " 'será',\n",
       " 'seremos',\n",
       " 'seréis',\n",
       " 'serán',\n",
       " 'sería',\n",
       " 'serías',\n",
       " 'seríamos',\n",
       " 'seríais',\n",
       " 'serían',\n",
       " 'era',\n",
       " 'eras',\n",
       " 'éramos',\n",
       " 'erais',\n",
       " 'eran',\n",
       " 'fui',\n",
       " 'fuiste',\n",
       " 'fue',\n",
       " 'fuimos',\n",
       " 'fuisteis',\n",
       " 'fueron',\n",
       " 'fuera',\n",
       " 'fueras',\n",
       " 'fuéramos',\n",
       " 'fuerais',\n",
       " 'fueran',\n",
       " 'fuese',\n",
       " 'fueses',\n",
       " 'fuésemos',\n",
       " 'fueseis',\n",
       " 'fuesen',\n",
       " 'sintiendo',\n",
       " 'sentido',\n",
       " 'sentida',\n",
       " 'sentidos',\n",
       " 'sentidas',\n",
       " 'siente',\n",
       " 'sentid',\n",
       " 'tengo',\n",
       " 'tienes',\n",
       " 'tiene',\n",
       " 'tenemos',\n",
       " 'tenéis',\n",
       " 'tienen',\n",
       " 'tenga',\n",
       " 'tengas',\n",
       " 'tengamos',\n",
       " 'tengáis',\n",
       " 'tengan',\n",
       " 'tendré',\n",
       " 'tendrás',\n",
       " 'tendrá',\n",
       " 'tendremos',\n",
       " 'tendréis',\n",
       " 'tendrán',\n",
       " 'tendría',\n",
       " 'tendrías',\n",
       " 'tendríamos',\n",
       " 'tendríais',\n",
       " 'tendrían',\n",
       " 'tenía',\n",
       " 'tenías',\n",
       " 'teníamos',\n",
       " 'teníais',\n",
       " 'tenían',\n",
       " 'tuve',\n",
       " 'tuviste',\n",
       " 'tuvo',\n",
       " 'tuvimos',\n",
       " 'tuvisteis',\n",
       " 'tuvieron',\n",
       " 'tuviera',\n",
       " 'tuvieras',\n",
       " 'tuviéramos',\n",
       " 'tuvierais',\n",
       " 'tuvieran',\n",
       " 'tuviese',\n",
       " 'tuvieses',\n",
       " 'tuviésemos',\n",
       " 'tuvieseis',\n",
       " 'tuviesen',\n",
       " 'teniendo',\n",
       " 'tenido',\n",
       " 'tenida',\n",
       " 'tenidos',\n",
       " 'tenidas',\n",
       " 'tened']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stop_words = list(sp.Defaults.stop_words)\n",
    "\n",
    "stopwords_español"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "39"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stop_words.index('cosas')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Guardar Stop Words\n",
    "with open('./Data/stopwords.txt', 'w') as f:\n",
    "    f.write(json.dumps(stop_words))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cargamos Stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "704"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Leer Stop words como set\n",
    "with open('./Data/stopwords.txt', 'r') as f:\n",
    "    stopwords = json.loads(f.read())\n",
    "len(stopwords)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Funciones Limpieza de Texto\n",
    "- Estandarizar tildes\n",
    "- Revisar abreviaturas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    '''Make text lowercase, remove text in square brackets, remove punctuation and remove words             containing numbers.'''\n",
    "    #text = fix_encoding(text)    \n",
    "    #text = re.sub('[‘’“”…«».]', '', text)\n",
    "    #text = re.sub('[\\n\\t]', ' ', text)\n",
    "    #text = re.sub(\"(\\\\d|\\\\W)+\", ' ', text)  # Removing special characters and digits    \n",
    "    #text = text.replace(\"_\",\"\")\n",
    "\n",
    "    text = text.lower()    \n",
    "    text = re.sub(\"\\d\", '',text)\n",
    "    text = re.sub(\"\\.\", '', text)\n",
    "    pattern = re.compile(r\"\"\"                  # Flag para iniciar el modo verbose\n",
    "              #(?:[A-Za-z]\\.|\\'|[A-Za-z])+            # Hace match con abreviaciones como U.S.A.Nombre's\n",
    "              #(?:[A-Za-z]\\.)+            # Hace match con abreviaciones como U.S.A.        \n",
    "               \\w+(?:\\w+)*         # Hace match con palabras completas\n",
    "              # | \\w+(?:-\\w+)*         # Hace match con palabras que pueden tener un guión interno\n",
    "              # \\$?\\d+(?:\\.\\d+)?%?  # Hace match con dinero o porcentajes como $15.5 o 100%\n",
    "              # \\.\\.\\.              # Hace match con puntos suspensivos\n",
    "              # [][.,;\"'?():-_`]    # Hace match con signos de puntuación\n",
    "              \"\"\", re.X)\n",
    "\n",
    "    result = pattern.findall(text)\n",
    "    #nltk.regexp_tokenize(text, pattern)\n",
    "    return result\n",
    "    \n",
    "#text = \"En los E.U. U.S.A. esa postal vale $15.50... (f.e.o.) `hola` Acoso Escolar (Bullying) en San Juan de Pasto.... J.D.A.A.S. baby Santiago's clubc slsda-sdasd-ss D.I.A. A.C.E. dia fiesta-buena\"\n",
    "#text = \"CAPACIDAD FUNGICIDA DE EXTRACTOS ETANOLICOS DE MATARRATON Gliricidia sepium (Jacq.) Kunth ex Walp Y AJI Capsicum annuum, SOBRE Moniliophthora roreri (Cif) Evans et al. , CAUSANTE DE LA MONILIASIS DEL CACAO. Por la prevalencia y severidad de la enfermedad Moniliasis, causada por el hongo fitopatógeno Moniliophothora roreri (Cif) Evans et al., y sus escazas medidas de control efectivas por sus altos costos económicos y ambientales, conduce a que se estudie el potencial biocida de extractos de Matarratón Gliricidia sepium y ají Capsicum annuum sobre el hongo Moniliophothora roreri en algunas variedades del cultivo de cacao Theobroma cacao; de esta forma contribuir en el manejo de dicha enfermedad. El estudio será llevado a cabo en las instalaciones de los laboratorios especializados y laboratorio de sanidad vegetal de la Universidad de Nariño, en donde se realizará un análisis fitoquímico preliminar de los extractos vegetales de Gliricidia sepium y Capsicum annuum, luego se determinará in vitro, la capacidad antifúngica de los extractos vegetales sobre el crecimiento micelial de M. roreri. y germinación de sus estructuras reproductivas y finalmente se evaluará el efecto de los extractos vegetales sobre la moniliasis en frutos de algunas variedades de cacao. Las plantas de G. sepium y C. annuum serán colectadas de fincas de agricultores de Corregimiento de San Luis Robles, municipio de Tumaco, junto con los frutos de algunos genotipos de cacao con los síntomas de la enfermedad. Los aislamientos del hongo M. roreri serán cultivados en cajas de Petri con medio de cultivo Agar Extracto de Malta. El diseño experimental constará de un diseño irrestrictamente al azar (D.I.A.) con arreglo factorial de 2x4, donde el factor A corresponderá a: los extractos etanólicos (E.E.1) de matarratón Gliricidia sepium L, (E.E.2) ají Capsicum annuum, un tratamiento testigo correspondiente a oxicloruro de cobre; y un testigo absoluto. El factor B está relacionado con las 4 concentraciones a evaluar (10 mg.mL-1, 100 mg.mL-1, 1.000 mg.mL-1 y 10.000 mg.mL-1). Los tratamientos: testigo comercial y testigo absoluto, serán evaluados en las mismas concentraciones de los extractos etanólicos. Además los tratamientos constarán de 3 repeticiones cada uno y en la que cada unidad experimental consistirá de una caja de petri. En cuanto a la pertinencia de la investigación, se debe tener en cuenta que el uso de fungicidas de síntesis química, o la disposición de material genético resistente no dilucida un panorama del todo satisfactorios para el manejo de la enfermedad, lo que hace que la utilización de extractos de plantas que contienen principios activos en alguno de sus órganos, los cuales, extraídos en forma adecuada y administrados en dosis suficientes, producen efectos curativos que permiten el manejo de insectos-plaga y de microorganismos fitopatógenos (Ramirez et al., 2010). Por lo anteriormente expuesto, se hace necesario efectuar este tipo de investigaciones que contribuyan a mejorar el manejo integrado de la Moniliasis, con el propósito de alcanzar mayor producción, rentabilidad y ante todo disminuir el riesgo ambiental de los cultivos de Cacao a nivel regional y nacional. cacao Producción y Sanidad Vegetal Ciencias Agrícolas GRUPO DE INVESTIGACION DE SANIDAD VEGETAL Control Biologico\"\n",
    "#clean_text(text)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Cargamos Datos Originales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "resumenes_docentes = pd.read_excel(\"./Data/Resumenes.xlsx\",sheet_name = \"Proyectos Docentes\")\n",
    "resumenes_estudiantes = pd.read_excel(\"./Data/Resumenes.xlsx\",sheet_name=\"studiantiles y Trabajos de G\")\n",
    "\n",
    "#Eliminamos  Columnas\n",
    "resumenes_docentes.drop(columns=['No.'], inplace=True)\n",
    "resumenes_estudiantes.drop(columns=['No.'], inplace=True)\n",
    "\n",
    "#Eliminamos NAN\n",
    "resumenes_docentes.dropna(inplace=True)\n",
    "resumenes_estudiantes.dropna(inplace=True)\n",
    "\n",
    "#Asignamos index\n",
    "resumenes_docentes['index'] = [*range(1,len(resumenes_docentes)+1)]\n",
    "resumenes_docentes.set_index('index', inplace=True)\n",
    "\n",
    "resumenes_estudiantes['index'] = [*range(1,len(resumenes_estudiantes)+1)]\n",
    "resumenes_estudiantes.set_index('index', inplace=True)\n",
    "\n",
    "#Asignamos Columnas\n",
    "resumenes_docentes.columns = [\"codigo\", \"titulo\", \"resumen\", \"estado\", \"id_autor\", \"nombre_autor\", \n",
    "                     \"programa\", \"facultad\", \"convocatoria\", \"grupo_investigacion\", \"linea_investigacion\", \"palabras_clave\"]\n",
    "\n",
    "resumenes_estudiantes.columns = ['codigo', 'titulo', 'resumen', 'estado', 'id_autor', 'nombre_autor',\n",
    "       'programa', 'departamento', 'facultad', 'nombre_asesor', 'convocatoria', 'grupo_investigacion', 'linea_investigacion', 'palabras_clave']\n",
    "\n",
    "\n",
    "#Eliminamos registros no encontrados\n",
    "resumenes_docentes['palabras_clave'] = resumenes_docentes['palabras_clave'].apply(lambda row: row if (row != 'No se encontraron palabras clave registradas') else \" \")\n",
    "resumenes_estudiantes['palabras_clave'] = resumenes_estudiantes['palabras_clave'].apply(lambda row: row if (row != 'No se encontraron palabras clave registradas') else \" \")\n",
    "\n",
    "#Convocatorias N/A\n",
    "resumenes_docentes['convocatoria'] = resumenes_docentes['convocatoria'].apply(lambda row: row if (row != 'N/A (Registrado)') else \" \")\n",
    "resumenes_estudiantes['convocatoria'] = resumenes_estudiantes['convocatoria'].apply(lambda row: row if (row != 'N/A (Registrado)') else \" \")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Corpus agregado al DF"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD:Notebooks/Notebooks_Preprocesamiento/tokenizacion.ipynb
   "execution_count": 1,
=======
   "execution_count": 8,
>>>>>>> b74a754ba5622b053af00716fdbf38cb13ef1146:Notebooks_Limpieza/tokenizacion.ipynb
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'resumenes_docentes' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-0f87c37fc547>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#Agregamos Columna de Corpus palabras tokenizadas\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m resumenes_docentes['corpus'] = resumenes_docentes.apply(lambda row: row['titulo']+' '+row['resumen']+' '+row['palabras_clave']+' '+row['programa']+' '+row['facultad']+' '+\n\u001b[0m\u001b[1;32m      3\u001b[0m                                                                     row['grupo_investigacion']+' '+row['linea_investigacion'],axis=1)\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m resumenes_estudiantes['corpus'] = resumenes_estudiantes.apply(lambda row: row['titulo']+' '+row['resumen']+' '+row['palabras_clave']+' '+row['programa']+' '+row['departamento']+' '+row['facultad']+' '+\n",
      "\u001b[0;31mNameError\u001b[0m: name 'resumenes_docentes' is not defined"
     ]
    }
   ],
   "source": [
    "#Agregamos Columna de Corpus palabras tokenizadas\n",
    "resumenes_docentes['corpus'] = resumenes_docentes.apply(lambda row: row['titulo']+' '+row['resumen']+' '+row['palabras_clave']+' '+row['facultad']+' '+row['programa']+' '+\n",
    "                                                                    row['grupo_investigacion']+' '+row['linea_investigacion'],axis=1)\n",
    "\n",
    "resumenes_estudiantes['corpus'] = resumenes_estudiantes.apply(lambda row: row['titulo']+' '+row['resumen']+' '+row['palabras_clave']+' '+row['facultad']+' '+row['departamento']+' '+row['programa']+' '+\n",
    "                                                                          row['grupo_investigacion']+' '+row['linea_investigacion'],axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Palabras Tokenizadas y Limpias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Eliminacion de stopwords en el corpus\n",
    "resumenes_docentes['palabras_corpus']=''\n",
    "for index, row in resumenes_docentes.iterrows():\n",
    "    palabras_clean = clean_text(row['corpus'])\n",
    "    #Agregamos el autor para que no sea lematizado\n",
    "    palabras_clean.extend(row['nombre_autor'].split())\n",
    "    palabras_clean.extend(row['convocatoria'].split())\n",
    "    palabras = [palabra for palabra in palabras_clean if not palabra in stopwords and len(palabra) >= 2]\n",
    "\n",
    "    resumenes_docentes.at[index, 'palabras_corpus'] = ' '.join(palabras)\n",
    "\n",
    "resumenes_estudiantes['palabras_corpus']=''\n",
    "for index, row in resumenes_estudiantes.iterrows():\n",
    "    palabras_clean = clean_text(row['corpus'])\n",
    "    #Agregamos el autor para que no sea lematizado\n",
    "    palabras_clean.extend(row['nombre_autor'].split())\n",
    "    palabras_clean.extend(row['nombre_asesor'].split())\n",
    "    palabras_clean.extend(row['convocatoria'].split())\n",
    "    palabras = [palabra for palabra in palabras_clean if not palabra in stopwords and len(palabra) >= 2]\n",
    "    \n",
    "    resumenes_estudiantes.at[index, 'palabras_corpus'] = ' '.join(palabras) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Palabras Tokenizadas y Limpias sin autores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "resumenes_docentes['palabras_no_autor']=''\n",
    "for index, row in resumenes_docentes.iterrows():\n",
    "    palabras_clean = clean_text(row['corpus'])\n",
    "    #Agregamos el autor para que no sea lematizado\n",
    "    palabras_clean.extend(row['convocatoria'].split())\n",
    "    palabras = [palabra for palabra in palabras_clean if not palabra in stopwords and len(palabra) >= 2]\n",
    "\n",
    "    resumenes_docentes.at[index, 'palabras_no_autor'] = ' '.join(palabras)\n",
    "\n",
    "resumenes_estudiantes['palabras_no_autor']=''\n",
    "for index, row in resumenes_estudiantes.iterrows():\n",
    "    palabras_clean = clean_text(row['corpus'])\n",
    "    #Agregamos el autor para que no sea lematizado\n",
    "    palabras_clean.extend(row['convocatoria'].split())\n",
    "    palabras = [palabra for palabra in palabras_clean if not palabra in stopwords and len(palabra) >= 2]\n",
    "    \n",
    "    resumenes_estudiantes.at[index, 'palabras_no_autor'] = ' '.join(palabras) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exportar Resumenes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "resumenes = [resumen for resumen in resumenes_docentes['palabras_no_autor']]\n",
    "resumenes.extend([resumen for resumen in resumenes_estudiantes['palabras_no_autor']])\n",
    "\n",
    "with open('./Data/resumenes.txt', 'w') as f:\n",
    "    for item in resumenes:\n",
    "        f.write(f'{item}\\n')     \n",
    "del(resumenes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": [
     "ssd"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>codigo</th>\n",
       "      <th>titulo</th>\n",
       "      <th>resumen</th>\n",
       "      <th>estado</th>\n",
       "      <th>id_autor</th>\n",
       "      <th>nombre_autor</th>\n",
       "      <th>programa</th>\n",
       "      <th>facultad</th>\n",
       "      <th>convocatoria</th>\n",
       "      <th>grupo_investigacion</th>\n",
       "      <th>linea_investigacion</th>\n",
       "      <th>palabras_clave</th>\n",
       "      <th>corpus</th>\n",
       "      <th>palabras_corpus</th>\n",
       "      <th>palabras_no_autor</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>index</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1464.0</td>\n",
       "      <td>\"Diagnóstico del impacto de las iniciativas em...</td>\n",
       "      <td>El emprendimiento es entre otras acepciones es...</td>\n",
       "      <td>Vencido</td>\n",
       "      <td>13515.0</td>\n",
       "      <td>Francisco Rafael Ayala</td>\n",
       "      <td>Diseño</td>\n",
       "      <td>Artes</td>\n",
       "      <td>Docente 2017</td>\n",
       "      <td>Currículo y Universidad</td>\n",
       "      <td>Curriculos pertinentes</td>\n",
       "      <td>Diagnóstico</td>\n",
       "      <td>\"Diagnóstico del impacto de las iniciativas em...</td>\n",
       "      <td>diagnóstico impacto iniciativas emprendedoras ...</td>\n",
       "      <td>diagnóstico impacto iniciativas emprendedoras ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1367.0</td>\n",
       "      <td>Acoso Escolar (Bullying) en San Juan de Pasto....</td>\n",
       "      <td>A nivel mundial, uno de cada tres escolares ha...</td>\n",
       "      <td>Prorroga</td>\n",
       "      <td>11902.0</td>\n",
       "      <td>Harvey Mauricio Herrera Lopez</td>\n",
       "      <td>Psicología</td>\n",
       "      <td>Ciencias Humanas</td>\n",
       "      <td>Docente 2017</td>\n",
       "      <td>Psicología y Salud</td>\n",
       "      <td>Aspectos Psicosociales en Procesos de Salud</td>\n",
       "      <td>Acoso Escolar</td>\n",
       "      <td>Acoso Escolar (Bullying) en San Juan de Pasto....</td>\n",
       "      <td>acoso escolar bullying san juan pasto modelo e...</td>\n",
       "      <td>acoso escolar bullying san juan pasto modelo e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1343.0</td>\n",
       "      <td>ACTIVIDAD ANTIBACTERIAL DE POLIFENOLES DEL AGU...</td>\n",
       "      <td>El cáncer gástrico (CG) es la principal causa ...</td>\n",
       "      <td>Vencido</td>\n",
       "      <td>10081.0</td>\n",
       "      <td>Nelson Humberto Hurtado Gutierrez</td>\n",
       "      <td>Química</td>\n",
       "      <td>Ciencias Exactas y Naturales</td>\n",
       "      <td>Docente 2016</td>\n",
       "      <td>GRUPO DE INVESTIGACIÓN EN PRODUCTOS DE IMPORTA...</td>\n",
       "      <td>Modelado molecular</td>\n",
       "      <td>cancer gastrico</td>\n",
       "      <td>ACTIVIDAD ANTIBACTERIAL DE POLIFENOLES DEL AGU...</td>\n",
       "      <td>actividad antibacterial polifenoles aguacate p...</td>\n",
       "      <td>actividad antibacterial polifenoles aguacate p...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       codigo                                             titulo  \\\n",
       "index                                                              \n",
       "1      1464.0  \"Diagnóstico del impacto de las iniciativas em...   \n",
       "2      1367.0  Acoso Escolar (Bullying) en San Juan de Pasto....   \n",
       "3      1343.0  ACTIVIDAD ANTIBACTERIAL DE POLIFENOLES DEL AGU...   \n",
       "\n",
       "                                                 resumen    estado  id_autor  \\\n",
       "index                                                                          \n",
       "1      El emprendimiento es entre otras acepciones es...   Vencido   13515.0   \n",
       "2      A nivel mundial, uno de cada tres escolares ha...  Prorroga   11902.0   \n",
       "3      El cáncer gástrico (CG) es la principal causa ...   Vencido   10081.0   \n",
       "\n",
       "                            nombre_autor    programa  \\\n",
       "index                                                  \n",
       "1                 Francisco Rafael Ayala      Diseño   \n",
       "2          Harvey Mauricio Herrera Lopez  Psicología   \n",
       "3      Nelson Humberto Hurtado Gutierrez     Química   \n",
       "\n",
       "                           facultad  convocatoria  \\\n",
       "index                                               \n",
       "1                             Artes  Docente 2017   \n",
       "2                  Ciencias Humanas  Docente 2017   \n",
       "3      Ciencias Exactas y Naturales  Docente 2016   \n",
       "\n",
       "                                     grupo_investigacion  \\\n",
       "index                                                      \n",
       "1                                Currículo y Universidad   \n",
       "2                                     Psicología y Salud   \n",
       "3      GRUPO DE INVESTIGACIÓN EN PRODUCTOS DE IMPORTA...   \n",
       "\n",
       "                               linea_investigacion   palabras_clave  \\\n",
       "index                                                                 \n",
       "1                           Curriculos pertinentes      Diagnóstico   \n",
       "2      Aspectos Psicosociales en Procesos de Salud    Acoso Escolar   \n",
       "3                               Modelado molecular  cancer gastrico   \n",
       "\n",
       "                                                  corpus  \\\n",
       "index                                                      \n",
       "1      \"Diagnóstico del impacto de las iniciativas em...   \n",
       "2      Acoso Escolar (Bullying) en San Juan de Pasto....   \n",
       "3      ACTIVIDAD ANTIBACTERIAL DE POLIFENOLES DEL AGU...   \n",
       "\n",
       "                                         palabras_corpus  \\\n",
       "index                                                      \n",
       "1      diagnóstico impacto iniciativas emprendedoras ...   \n",
       "2      acoso escolar bullying san juan pasto modelo e...   \n",
       "3      actividad antibacterial polifenoles aguacate p...   \n",
       "\n",
       "                                       palabras_no_autor  \n",
       "index                                                     \n",
       "1      diagnóstico impacto iniciativas emprendedoras ...  \n",
       "2      acoso escolar bullying san juan pasto modelo e...  \n",
       "3      actividad antibacterial polifenoles aguacate p...  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resumenes_docentes.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experimental"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "resumenes_docentes.to_json(r'./Data/ResumenesDocentes.json')\n",
    "resumenes_estudiantes.to_json(r'./Data/ResumenesEstudiante.json')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Guardar CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "resumenes_docentes.to_csv(r'./Data/ResumenesDocentes.csv')\n",
    "resumenes_estudiantes.to_csv(r'./Data/ResumenesEstudiantes.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lemas Completo Resumen 1\n"
     ]
    }
   ],
   "source": [
    "json_resumen['lemas'] = ''\n",
    "for index, row in json_resumen.iterrows():\n",
    "    if( index > 1): break\n",
    "    vocabulario = row['vocabulario']\n",
    "    json_resumen.at[index, 'lemas'] = [lemmatizer(palabra) for palabra in vocabulario]\n",
    "    print(f'Lemas Completo Resumen {index}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Carga de datos de prueba limpios\n",
    "\n",
    "**ejecutar a partir de aqui para los LEMAS**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lematizar Palabras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cargar Datos ya procesados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import ast\n",
    "\n",
    "resumenes_docentes = pd.read_csv(\"./Data/ResumenesDocentes.csv\", index_col=0)\n",
    "resumenes_estudiantes = pd.read_csv(\"./Data/ResumenesEstudiantes.csv\", index_col=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>codigo</th>\n",
       "      <th>titulo</th>\n",
       "      <th>resumen</th>\n",
       "      <th>estado</th>\n",
       "      <th>id_autor</th>\n",
       "      <th>nombre_autor</th>\n",
       "      <th>programa</th>\n",
       "      <th>facultad</th>\n",
       "      <th>convocatoria</th>\n",
       "      <th>grupo_investigacion</th>\n",
       "      <th>linea_investigacion</th>\n",
       "      <th>palabras_clave</th>\n",
       "      <th>corpus</th>\n",
       "      <th>palabras_corpus</th>\n",
       "      <th>lemas_corpus</th>\n",
       "      <th>lemas_corpus_clean</th>\n",
       "      <th>vocabulario</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>index</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1464.0</td>\n",
       "      <td>\"Diagnóstico del impacto de las iniciativas em...</td>\n",
       "      <td>El emprendimiento es entre otras acepciones es...</td>\n",
       "      <td>Vencido</td>\n",
       "      <td>13515.0</td>\n",
       "      <td>Francisco Rafael Ayala</td>\n",
       "      <td>Diseño</td>\n",
       "      <td>Artes</td>\n",
       "      <td>Docente 2017</td>\n",
       "      <td>Currículo y Universidad</td>\n",
       "      <td>Curriculos pertinentes</td>\n",
       "      <td>Diagnóstico</td>\n",
       "      <td>\"Diagnóstico del impacto de las iniciativas em...</td>\n",
       "      <td>diagnóstico impacto iniciativas emprendedoras ...</td>\n",
       "      <td>diagnóstico impactar iniciativo emprendedor e...</td>\n",
       "      <td>diagnostico impactar iniciativo emprendedor e...</td>\n",
       "      <td>['laboral', 'privar', 'conveniente', 'necesida...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       codigo                                             titulo  \\\n",
       "index                                                              \n",
       "1      1464.0  \"Diagnóstico del impacto de las iniciativas em...   \n",
       "\n",
       "                                                 resumen   estado  id_autor  \\\n",
       "index                                                                         \n",
       "1      El emprendimiento es entre otras acepciones es...  Vencido   13515.0   \n",
       "\n",
       "                 nombre_autor programa facultad  convocatoria  \\\n",
       "index                                                           \n",
       "1      Francisco Rafael Ayala   Diseño    Artes  Docente 2017   \n",
       "\n",
       "           grupo_investigacion     linea_investigacion palabras_clave  \\\n",
       "index                                                                   \n",
       "1      Currículo y Universidad  Curriculos pertinentes    Diagnóstico   \n",
       "\n",
       "                                                  corpus  \\\n",
       "index                                                      \n",
       "1      \"Diagnóstico del impacto de las iniciativas em...   \n",
       "\n",
       "                                         palabras_corpus  \\\n",
       "index                                                      \n",
       "1      diagnóstico impacto iniciativas emprendedoras ...   \n",
       "\n",
       "                                            lemas_corpus  \\\n",
       "index                                                      \n",
       "1       diagnóstico impactar iniciativo emprendedor e...   \n",
       "\n",
       "                                      lemas_corpus_clean  \\\n",
       "index                                                      \n",
       "1       diagnostico impactar iniciativo emprendedor e...   \n",
       "\n",
       "                                             vocabulario  \n",
       "index                                                     \n",
       "1      ['laboral', 'privar', 'conveniente', 'necesida...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resumenes_docentes.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Funcion de Lematizar una palabra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importar spacy para lemmatizar palabras\n",
    "import spacy\n",
    "import difflib\n",
    "nlp = spacy.load('es_core_news_sm')\n",
    "\n",
    "#Eliminacion de Tildes y dialisis\n",
    "#Diccionario lemas\n",
    "diccionario_lemas = dict()\n",
    "\n",
    "def lemmatizer(text):\n",
    "  #Key Lema\n",
    "  #Value las Palabras Originales\n",
    "  normalizar = str.maketrans('áéíóúü','aeiouu')\n",
    "  \n",
    "  lemas = ''\n",
    "  lemas_cleaned = ''\n",
    "\n",
    "  doc = nlp(text)\n",
    "  for word in doc:\n",
    "    #Eliminamos tildes de palabras\n",
    "    cleaned_lema = word.lemma_.translate(normalizar).lower()\n",
    "    cleaned_word = word.text.translate(normalizar).lower()\n",
    "\n",
    "    #Agreamos el corpus de lemas original\n",
    "    lemas = lemas + ' ' + word.lemma_\n",
    "  \n",
    "    #Obtenemos Lista de palabras asociadas al lema\n",
    "    list_lemas = diccionario_lemas.get(cleaned_lema)\n",
    "    \n",
    "    if(list_lemas == None):\n",
    "        similar_word = difflib.get_close_matches(cleaned_lema, diccionario_lemas.keys(), n=1, cutoff=0.9)\n",
    "        #print(similar_word)\n",
    "        cleaned_lema = similar_word[0] if len(similar_word) > 0 else cleaned_lema\n",
    "    \n",
    "    #Agregamos el corpus de lemas sin tildes que es el que se va a instanciar\n",
    "    lemas_cleaned = lemas_cleaned + ' ' + cleaned_lema\n",
    "    \n",
    "    #Verificar si el Lema existe\n",
    "    if( list_lemas == None):\n",
    "      #Agregamos palabra original y lema\n",
    "      if(cleaned_lema == cleaned_word):\n",
    "        diccionario_lemas[cleaned_lema] = [ cleaned_word ]\n",
    "      else:\n",
    "        diccionario_lemas[cleaned_lema] = [ cleaned_word, cleaned_lema ]\n",
    "    else:\n",
    "      #Revisamos si es una nueva palabra\n",
    "      if cleaned_word not in list_lemas:\n",
    "        diccionario_lemas[cleaned_lema].append(cleaned_word)\n",
    "\n",
    "    #print(' '.join([word.lema_ for word in doc]))\n",
    "  #print(lemas_cleaned)\n",
    "  return [lemas, lemas_cleaned]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "diccionario_lemas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Agregar Lemas a Docentes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lemas como corpus - DOCENTES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lemas Completo Resumen 1\n",
      "Lemas Completo Resumen 2\n",
      "Lemas Completo Resumen 3\n",
      "Lemas Completo Resumen 4\n",
      "Lemas Completo Resumen 5\n",
      "Lemas Completo Resumen 6\n",
      "Lemas Completo Resumen 7\n",
      "Lemas Completo Resumen 8\n",
      "Lemas Completo Resumen 9\n",
      "Lemas Completo Resumen 10\n",
      "Lemas Completo Resumen 11\n",
      "Lemas Completo Resumen 12\n",
      "Lemas Completo Resumen 13\n",
      "Lemas Completo Resumen 14\n",
      "Lemas Completo Resumen 15\n",
      "Lemas Completo Resumen 16\n",
      "Lemas Completo Resumen 17\n",
      "Lemas Completo Resumen 18\n",
      "Lemas Completo Resumen 19\n",
      "Lemas Completo Resumen 20\n",
      "Lemas Completo Resumen 21\n",
      "Lemas Completo Resumen 22\n",
      "Lemas Completo Resumen 23\n",
      "Lemas Completo Resumen 24\n",
      "Lemas Completo Resumen 25\n",
      "Lemas Completo Resumen 26\n",
      "Lemas Completo Resumen 27\n",
      "Lemas Completo Resumen 28\n",
      "Lemas Completo Resumen 29\n",
      "Lemas Completo Resumen 30\n",
      "Lemas Completo Resumen 31\n",
      "Lemas Completo Resumen 32\n",
      "Lemas Completo Resumen 33\n",
      "Lemas Completo Resumen 34\n",
      "Lemas Completo Resumen 35\n",
      "Lemas Completo Resumen 36\n",
      "Lemas Completo Resumen 37\n",
      "Lemas Completo Resumen 38\n",
      "Lemas Completo Resumen 39\n",
      "Lemas Completo Resumen 40\n",
      "Lemas Completo Resumen 41\n",
      "Lemas Completo Resumen 42\n",
      "Lemas Completo Resumen 43\n",
      "Lemas Completo Resumen 44\n",
      "Lemas Completo Resumen 45\n",
      "Lemas Completo Resumen 46\n",
      "Lemas Completo Resumen 47\n",
      "Lemas Completo Resumen 48\n",
      "Lemas Completo Resumen 49\n",
      "Lemas Completo Resumen 50\n",
      "Lemas Completo Resumen 51\n",
      "Lemas Completo Resumen 52\n",
      "Lemas Completo Resumen 53\n",
      "Lemas Completo Resumen 54\n",
      "Lemas Completo Resumen 55\n",
      "Lemas Completo Resumen 56\n",
      "Lemas Completo Resumen 57\n",
      "Lemas Completo Resumen 58\n",
      "Lemas Completo Resumen 59\n",
      "Lemas Completo Resumen 60\n",
      "Lemas Completo Resumen 61\n",
      "Lemas Completo Resumen 62\n",
      "Lemas Completo Resumen 63\n",
      "Lemas Completo Resumen 64\n",
      "Lemas Completo Resumen 65\n",
      "Lemas Completo Resumen 66\n",
      "Lemas Completo Resumen 67\n",
      "Lemas Completo Resumen 68\n",
      "Lemas Completo Resumen 69\n",
      "Lemas Completo Resumen 70\n",
      "Lemas Completo Resumen 71\n",
      "Lemas Completo Resumen 72\n",
      "Lemas Completo Resumen 73\n",
      "Lemas Completo Resumen 74\n",
      "Lemas Completo Resumen 75\n",
      "Lemas Completo Resumen 76\n",
      "Lemas Completo Resumen 77\n",
      "Lemas Completo Resumen 78\n",
      "Lemas Completo Resumen 79\n",
      "Lemas Completo Resumen 80\n",
      "Lemas Completo Resumen 81\n",
      "Lemas Completo Resumen 82\n",
      "Lemas Completo Resumen 83\n",
      "Lemas Completo Resumen 84\n",
      "Lemas Completo Resumen 85\n",
      "Lemas Completo Resumen 86\n",
      "Lemas Completo Resumen 87\n",
      "Lemas Completo Resumen 88\n",
      "Lemas Completo Resumen 89\n",
      "Lemas Completo Resumen 90\n",
      "Lemas Completo Resumen 91\n",
      "Lemas Completo Resumen 92\n",
      "Lemas Completo Resumen 93\n",
      "Lemas Completo Resumen 94\n",
      "Lemas Completo Resumen 95\n",
      "Lemas Completo Resumen 96\n",
      "Lemas Completo Resumen 97\n",
      "Lemas Completo Resumen 98\n",
      "Lemas Completo Resumen 99\n",
      "Lemas Completo Resumen 100\n",
      "Lemas Completo Resumen 101\n",
      "Lemas Completo Resumen 102\n",
      "Lemas Completo Resumen 103\n",
      "Lemas Completo Resumen 104\n",
      "Lemas Completo Resumen 105\n",
      "Lemas Completo Resumen 106\n",
      "Lemas Completo Resumen 107\n",
      "Lemas Completo Resumen 108\n",
      "Lemas Completo Resumen 109\n",
      "Lemas Completo Resumen 110\n",
      "Lemas Completo Resumen 111\n",
      "Lemas Completo Resumen 112\n",
      "Lemas Completo Resumen 113\n",
      "Lemas Completo Resumen 114\n",
      "Lemas Completo Resumen 115\n",
      "Lemas Completo Resumen 116\n",
      "Lemas Completo Resumen 117\n",
      "Lemas Completo Resumen 118\n",
      "Lemas Completo Resumen 119\n",
      "Lemas Completo Resumen 120\n",
      "Lemas Completo Resumen 121\n",
      "Lemas Completo Resumen 122\n",
      "Lemas Completo Resumen 123\n",
      "Lemas Completo Resumen 124\n",
      "Lemas Completo Resumen 125\n",
      "Lemas Completo Resumen 126\n",
      "Lemas Completo Resumen 127\n",
      "Lemas Completo Resumen 128\n",
      "Lemas Completo Resumen 129\n",
      "Lemas Completo Resumen 130\n",
      "Lemas Completo Resumen 131\n",
      "Lemas Completo Resumen 132\n",
      "Lemas Completo Resumen 133\n",
      "Lemas Completo Resumen 134\n",
      "Lemas Completo Resumen 135\n",
      "Lemas Completo Resumen 136\n",
      "Lemas Completo Resumen 137\n",
      "Lemas Completo Resumen 138\n",
      "Lemas Completo Resumen 139\n",
      "Lemas Completo Resumen 140\n",
      "Lemas Completo Resumen 141\n",
      "Lemas Completo Resumen 142\n",
      "Lemas Completo Resumen 143\n",
      "Lemas Completo Resumen 144\n",
      "Lemas Completo Resumen 145\n",
      "Lemas Completo Resumen 146\n",
      "Lemas Completo Resumen 147\n",
      "Lemas Completo Resumen 148\n",
      "Lemas Completo Resumen 149\n",
      "Lemas Completo Resumen 150\n",
      "Lemas Completo Resumen 151\n",
      "Lemas Completo Resumen 152\n",
      "Lemas Completo Resumen 153\n",
      "Lemas Completo Resumen 154\n",
      "Lemas Completo Resumen 155\n",
      "Lemas Completo Resumen 156\n",
      "Lemas Completo Resumen 157\n",
      "Lemas Completo Resumen 158\n",
      "Lemas Completo Resumen 159\n",
      "Lemas Completo Resumen 160\n",
      "Lemas Completo Resumen 161\n",
      "Lemas Completo Resumen 162\n",
      "Lemas Completo Resumen 163\n",
      "Lemas Completo Resumen 164\n",
      "Lemas Completo Resumen 165\n",
      "Lemas Completo Resumen 166\n",
      "Lemas Completo Resumen 167\n",
      "Lemas Completo Resumen 168\n",
      "Lemas Completo Resumen 169\n",
      "Lemas Completo Resumen 170\n",
      "Lemas Completo Resumen 171\n",
      "Lemas Completo Resumen 172\n",
      "Lemas Completo Resumen 173\n",
      "Lemas Completo Resumen 174\n",
      "Lemas Completo Resumen 175\n",
      "Lemas Completo Resumen 176\n",
      "Lemas Completo Resumen 177\n",
      "Lemas Completo Resumen 178\n",
      "Lemas Completo Resumen 179\n",
      "Lemas Completo Resumen 180\n",
      "Lemas Completo Resumen 181\n",
      "Lemas Completo Resumen 182\n",
      "Lemas Completo Resumen 183\n",
      "Lemas Completo Resumen 184\n",
      "Lemas Completo Resumen 185\n",
      "Lemas Completo Resumen 186\n",
      "Lemas Completo Resumen 187\n",
      "Lemas Completo Resumen 188\n",
      "Lemas Completo Resumen 189\n",
      "Lemas Completo Resumen 190\n",
      "Lemas Completo Resumen 191\n",
      "Lemas Completo Resumen 192\n",
      "Lemas Completo Resumen 193\n",
      "Lemas Completo Resumen 194\n",
      "Lemas Completo Resumen 195\n",
      "Lemas Completo Resumen 196\n",
      "Lemas Completo Resumen 197\n",
      "Lemas Completo Resumen 198\n",
      "Lemas Completo Resumen 199\n",
      "Lemas Completo Resumen 200\n",
      "Lemas Completo Resumen 201\n",
      "Lemas Completo Resumen 202\n",
      "Lemas Completo Resumen 203\n",
      "Lemas Completo Resumen 204\n",
      "Lemas Completo Resumen 205\n",
      "Lemas Completo Resumen 206\n",
      "Lemas Completo Resumen 207\n",
      "Lemas Completo Resumen 208\n",
      "Lemas Completo Resumen 209\n",
      "Lemas Completo Resumen 210\n",
      "Lemas Completo Resumen 211\n",
      "Lemas Completo Resumen 212\n",
      "Lemas Completo Resumen 213\n",
      "Lemas Completo Resumen 214\n",
      "Lemas Completo Resumen 215\n",
      "Lemas Completo Resumen 216\n",
      "Lemas Completo Resumen 217\n",
      "Lemas Completo Resumen 218\n",
      "Lemas Completo Resumen 219\n",
      "Lemas Completo Resumen 220\n",
      "Lemas Completo Resumen 221\n",
      "Lemas Completo Resumen 222\n",
      "Lemas Completo Resumen 223\n",
      "Lemas Completo Resumen 224\n",
      "Lemas Completo Resumen 225\n",
      "Lemas Completo Resumen 226\n",
      "Lemas Completo Resumen 227\n",
      "Lemas Completo Resumen 228\n",
      "Lemas Completo Resumen 229\n",
      "Lemas Completo Resumen 230\n",
      "Lemas Completo Resumen 231\n",
      "Lemas Completo Resumen 232\n",
      "Lemas Completo Resumen 233\n",
      "Lemas Completo Resumen 234\n",
      "Lemas Completo Resumen 235\n",
      "Lemas Completo Resumen 236\n",
      "Lemas Completo Resumen 237\n",
      "Lemas Completo Resumen 238\n",
      "Lemas Completo Resumen 239\n",
      "Lemas Completo Resumen 240\n",
      "Lemas Completo Resumen 241\n",
      "Lemas Completo Resumen 242\n",
      "Lemas Completo Resumen 243\n",
      "Lemas Completo Resumen 244\n",
      "Lemas Completo Resumen 245\n",
      "Lemas Completo Resumen 246\n",
      "Lemas Completo Resumen 247\n",
      "Lemas Completo Resumen 248\n",
      "Lemas Completo Resumen 249\n",
      "Lemas Completo Resumen 250\n",
      "Lemas Completo Resumen 251\n",
      "Lemas Completo Resumen 252\n",
      "Lemas Completo Resumen 253\n",
      "Lemas Completo Resumen 254\n",
      "Lemas Completo Resumen 255\n",
      "Lemas Completo Resumen 256\n",
      "Lemas Completo Resumen 257\n",
      "Lemas Completo Resumen 258\n",
      "Lemas Completo Resumen 259\n",
      "Lemas Completo Resumen 260\n",
      "Lemas Completo Resumen 261\n",
      "Lemas Completo Resumen 262\n",
      "Lemas Completo Resumen 263\n",
      "Lemas Completo Resumen 264\n",
      "Lemas Completo Resumen 265\n",
      "Lemas Completo Resumen 266\n",
      "Lemas Completo Resumen 267\n",
      "Lemas Completo Resumen 268\n",
      "Lemas Completo Resumen 269\n",
      "Lemas Completo Resumen 270\n",
      "Lemas Completo Resumen 271\n",
      "Lemas Completo Resumen 272\n",
      "Lemas Completo Resumen 273\n",
      "Lemas Completo Resumen 274\n",
      "Lemas Completo Resumen 275\n",
      "Lemas Completo Resumen 276\n",
      "Lemas Completo Resumen 277\n",
      "Lemas Completo Resumen 278\n",
      "Lemas Completo Resumen 279\n",
      "Lemas Completo Resumen 280\n",
      "Lemas Completo Resumen 281\n",
      "Lemas Completo Resumen 282\n",
      "Lemas Completo Resumen 283\n",
      "Lemas Completo Resumen 284\n",
      "Lemas Completo Resumen 285\n",
      "Lemas Completo Resumen 286\n",
      "Lemas Completo Resumen 287\n",
      "Lemas Completo Resumen 288\n",
      "Lemas Completo Resumen 289\n",
      "Lemas Completo Resumen 290\n",
      "Lemas Completo Resumen 291\n",
      "Lemas Completo Resumen 292\n",
      "Lemas Completo Resumen 293\n",
      "Lemas Completo Resumen 294\n",
      "Lemas Completo Resumen 295\n",
      "Lemas Completo Resumen 296\n",
      "Lemas Completo Resumen 297\n",
      "Lemas Completo Resumen 298\n",
      "Lemas Completo Resumen 299\n",
      "Lemas Completo Resumen 300\n",
      "Lemas Completo Resumen 301\n",
      "Lemas Completo Resumen 302\n",
      "Lemas Completo Resumen 303\n",
      "Lemas Completo Resumen 304\n",
      "Lemas Completo Resumen 305\n",
      "Lemas Completo Resumen 306\n",
      "Lemas Completo Resumen 307\n",
      "Lemas Completo Resumen 308\n"
     ]
    }
   ],
   "source": [
    "resumenes_docentes['lemas_corpus'] = ''\n",
    "resumenes_docentes['lemas_corpus_clean'] = ''\n",
    "resumenes_docentes['vocabulario'] = ''\n",
    "for index, row in resumenes_docentes.iterrows():\n",
    "    #if( index > 3): break\n",
    "    #palabras = ast.literal_eval(row['palabras'])\n",
    "    lemas = lemmatizer(row['palabras_corpus'])\n",
    "    #lemas_corpus = lemas_corpus.replace(' .', '.') # espacios de abreviaturas\n",
    "    #lemas_corpus = list(lemas[0].split())\n",
    "    lemas_corpus = lemas[0]\n",
    "    lemas_corpus_clean = lemas[1]\n",
    "    vocabulario_lemas = set(lemas_corpus_clean.split())\n",
    "    \n",
    "    resumenes_docentes.at[index, 'lemas_corpus'] = lemas_corpus\n",
    "    resumenes_docentes.at[index, 'lemas_corpus_clean'] = lemas_corpus_clean\n",
    "    resumenes_docentes.at[index, 'vocabulario'] = vocabulario_lemas\n",
    "    print(f'Lemas Completo Resumen {index}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lemas como corpus - ESTUDIANTES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lemas Completo Resumen 1\n",
      "Lemas Completo Resumen 2\n",
      "Lemas Completo Resumen 3\n",
      "Lemas Completo Resumen 4\n",
      "Lemas Completo Resumen 5\n",
      "Lemas Completo Resumen 6\n",
      "Lemas Completo Resumen 7\n",
      "Lemas Completo Resumen 8\n",
      "Lemas Completo Resumen 9\n",
      "Lemas Completo Resumen 10\n",
      "Lemas Completo Resumen 11\n",
      "Lemas Completo Resumen 12\n",
      "Lemas Completo Resumen 13\n",
      "Lemas Completo Resumen 14\n",
      "Lemas Completo Resumen 15\n",
      "Lemas Completo Resumen 16\n",
      "Lemas Completo Resumen 17\n",
      "Lemas Completo Resumen 18\n",
      "Lemas Completo Resumen 19\n",
      "Lemas Completo Resumen 20\n",
      "Lemas Completo Resumen 21\n",
      "Lemas Completo Resumen 22\n",
      "Lemas Completo Resumen 23\n",
      "Lemas Completo Resumen 24\n",
      "Lemas Completo Resumen 25\n",
      "Lemas Completo Resumen 26\n",
      "Lemas Completo Resumen 27\n",
      "Lemas Completo Resumen 28\n",
      "Lemas Completo Resumen 29\n",
      "Lemas Completo Resumen 30\n",
      "Lemas Completo Resumen 31\n",
      "Lemas Completo Resumen 32\n",
      "Lemas Completo Resumen 33\n",
      "Lemas Completo Resumen 34\n",
      "Lemas Completo Resumen 35\n",
      "Lemas Completo Resumen 36\n",
      "Lemas Completo Resumen 37\n",
      "Lemas Completo Resumen 38\n",
      "Lemas Completo Resumen 39\n",
      "Lemas Completo Resumen 40\n",
      "Lemas Completo Resumen 41\n",
      "Lemas Completo Resumen 42\n",
      "Lemas Completo Resumen 43\n",
      "Lemas Completo Resumen 44\n",
      "Lemas Completo Resumen 45\n",
      "Lemas Completo Resumen 46\n",
      "Lemas Completo Resumen 47\n",
      "Lemas Completo Resumen 48\n",
      "Lemas Completo Resumen 49\n",
      "Lemas Completo Resumen 50\n",
      "Lemas Completo Resumen 51\n",
      "Lemas Completo Resumen 52\n",
      "Lemas Completo Resumen 53\n",
      "Lemas Completo Resumen 54\n",
      "Lemas Completo Resumen 55\n",
      "Lemas Completo Resumen 56\n",
      "Lemas Completo Resumen 57\n",
      "Lemas Completo Resumen 58\n",
      "Lemas Completo Resumen 59\n",
      "Lemas Completo Resumen 60\n",
      "Lemas Completo Resumen 61\n",
      "Lemas Completo Resumen 62\n",
      "Lemas Completo Resumen 63\n",
      "Lemas Completo Resumen 64\n",
      "Lemas Completo Resumen 65\n",
      "Lemas Completo Resumen 66\n",
      "Lemas Completo Resumen 67\n",
      "Lemas Completo Resumen 68\n",
      "Lemas Completo Resumen 69\n",
      "Lemas Completo Resumen 70\n",
      "Lemas Completo Resumen 71\n",
      "Lemas Completo Resumen 72\n",
      "Lemas Completo Resumen 73\n",
      "Lemas Completo Resumen 74\n",
      "Lemas Completo Resumen 75\n",
      "Lemas Completo Resumen 76\n",
      "Lemas Completo Resumen 77\n",
      "Lemas Completo Resumen 78\n",
      "Lemas Completo Resumen 79\n",
      "Lemas Completo Resumen 80\n",
      "Lemas Completo Resumen 81\n",
      "Lemas Completo Resumen 82\n",
      "Lemas Completo Resumen 83\n",
      "Lemas Completo Resumen 84\n",
      "Lemas Completo Resumen 85\n",
      "Lemas Completo Resumen 86\n",
      "Lemas Completo Resumen 87\n",
      "Lemas Completo Resumen 88\n",
      "Lemas Completo Resumen 89\n",
      "Lemas Completo Resumen 90\n",
      "Lemas Completo Resumen 91\n",
      "Lemas Completo Resumen 92\n",
      "Lemas Completo Resumen 93\n",
      "Lemas Completo Resumen 94\n",
      "Lemas Completo Resumen 95\n",
      "Lemas Completo Resumen 96\n",
      "Lemas Completo Resumen 97\n",
      "Lemas Completo Resumen 98\n",
      "Lemas Completo Resumen 99\n",
      "Lemas Completo Resumen 100\n",
      "Lemas Completo Resumen 101\n",
      "Lemas Completo Resumen 102\n",
      "Lemas Completo Resumen 103\n",
      "Lemas Completo Resumen 104\n",
      "Lemas Completo Resumen 105\n",
      "Lemas Completo Resumen 106\n",
      "Lemas Completo Resumen 107\n",
      "Lemas Completo Resumen 108\n",
      "Lemas Completo Resumen 109\n",
      "Lemas Completo Resumen 110\n",
      "Lemas Completo Resumen 111\n",
      "Lemas Completo Resumen 112\n",
      "Lemas Completo Resumen 113\n",
      "Lemas Completo Resumen 114\n",
      "Lemas Completo Resumen 115\n",
      "Lemas Completo Resumen 116\n",
      "Lemas Completo Resumen 117\n",
      "Lemas Completo Resumen 118\n",
      "Lemas Completo Resumen 119\n",
      "Lemas Completo Resumen 120\n",
      "Lemas Completo Resumen 121\n",
      "Lemas Completo Resumen 122\n",
      "Lemas Completo Resumen 123\n",
      "Lemas Completo Resumen 124\n",
      "Lemas Completo Resumen 125\n",
      "Lemas Completo Resumen 126\n",
      "Lemas Completo Resumen 127\n",
      "Lemas Completo Resumen 128\n",
      "Lemas Completo Resumen 129\n",
      "Lemas Completo Resumen 130\n",
      "Lemas Completo Resumen 131\n",
      "Lemas Completo Resumen 132\n",
      "Lemas Completo Resumen 133\n",
      "Lemas Completo Resumen 134\n",
      "Lemas Completo Resumen 135\n",
      "Lemas Completo Resumen 136\n",
      "Lemas Completo Resumen 137\n",
      "Lemas Completo Resumen 138\n",
      "Lemas Completo Resumen 139\n",
      "Lemas Completo Resumen 140\n",
      "Lemas Completo Resumen 141\n",
      "Lemas Completo Resumen 142\n",
      "Lemas Completo Resumen 143\n"
     ]
    }
   ],
   "source": [
    "resumenes_estudiantes['lemas_corpus'] = ''\n",
    "resumenes_estudiantes['lemas_corpus_clean'] = ''\n",
    "resumenes_estudiantes['vocabulario'] = ''\n",
    "for index, row in resumenes_estudiantes.iterrows():\n",
    "    #if( index > 1): break\n",
    "    lemas = lemmatizer(row['palabras_corpus'])\n",
    "    lemas_corpus = lemas[0]\n",
    "    lemas_corpus_clean = lemas[1]\n",
    "    vocabulario_lemas = set(lemas_corpus_clean.split())\n",
    "    \n",
    "    resumenes_estudiantes.at[index, 'lemas_corpus'] = lemas_corpus\n",
    "    resumenes_estudiantes.at[index, 'lemas_corpus_clean'] = lemas_corpus_clean   \n",
    "    resumenes_estudiantes.at[index, 'vocabulario'] = vocabulario_lemas\n",
    "    \n",
    "    print(f'Lemas Completo Resumen {index}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Guardamos diccionario de Lemas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "resumenes_docentes.to_csv(r'./Data/ResumenesDocentes.csv')\n",
    "resumenes_estudiantes.to_csv(r'./Data/ResumenesEstudiantes.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Guardamos diccionario como JSON\n",
    "import json\n",
    "\n",
    "with open('./Data/diccionario-lemas.json', 'w') as f:\n",
    "    json.dump(diccionario_lemas, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Lectura de lemas \n",
    "import json\n",
    "with open('./Data/diccionario-lemas.json', 'r') as f:\n",
    "    diccionario_lemas = json.loads(f.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8673"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(diccionario_lemas)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Agregar Lemas a Estudiantes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "lemas = [ lemmatizer(palabra) for palabra in vocabulario]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
