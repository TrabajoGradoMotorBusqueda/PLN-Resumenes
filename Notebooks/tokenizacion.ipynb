{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Limpieza y Tokenizacion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Cargamos librerias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import spacy\n",
    "#sp = spacy.load('es_core_news_sm')\n",
    "#stop_words = sp.Defaults.stop_words\n",
    "#from nltk.corpus import stopwords\n",
    "#stopwords_español = stopwords.words('spanish')\n",
    "#aditionalwords= [palabra for palabra in stopwords_español if palabra not in stop_words ]\n",
    "#stop_words.extend(aditionalwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'stop_words' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-4518ef4f3ca1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#Guardar Stop Words\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'./Data/stopwords.txt'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'w'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdumps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstop_words\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'stop_words' is not defined"
     ]
    }
   ],
   "source": [
    "#Guardar Stop Words\n",
    "with open('./Data/stopwords.txt', 'w') as f:\n",
    "    f.write(json.dumps(stop_words))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cargamos Stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "704"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Leer Stop words como set\n",
    "with open('./Data/stopwords.txt', 'r') as f:\n",
    "    stopwords = json.loads(f.read())\n",
    "len(stopwords)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Funciones Limpieza de Texto\n",
    "- Estandarizar tildes\n",
    "- Revisar abreviaturas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    '''Make text lowercase, remove text in square brackets, remove punctuation and remove words             containing numbers.'''\n",
    "    #text = fix_encoding(text)    \n",
    "    #text = re.sub('[‘’“”…«».]', '', text)\n",
    "    #text = re.sub('[\\n\\t]', ' ', text)\n",
    "    #text = re.sub(\"(\\\\d|\\\\W)+\", ' ', text)  # Removing special characters and digits    \n",
    "    #text = text.replace(\"_\",\"\")\n",
    "\n",
    "    text = text.lower()\n",
    "    text = re.sub(\"\\d\", '',text)\n",
    "    pattern = re.compile(r\"\"\"                  # Flag para iniciar el modo verbose\n",
    "              #(?:[A-Za-z]\\.|\\'|[A-Za-z])+            # Hace match con abreviaciones como U.S.A.Nombre's\n",
    "              (?:[A-Za-z]\\.)+            # Hace match con abreviaciones como U.S.A.        \n",
    "              | \\w+(?:-\\w+)*         # Hace match con palabras que pueden tener un guión interno\n",
    "              # \\$?\\d+(?:\\.\\d+)?%?  # Hace match con dinero o porcentajes como $15.5 o 100%\n",
    "              # \\.\\.\\.              # Hace match con puntos suspensivos\n",
    "              # [][.,;\"'?():-_`]    # Hace match con signos de puntuación\n",
    "              \"\"\", re.X)\n",
    "\n",
    "    result = pattern.findall(text)\n",
    "    #nltk.regexp_tokenize(text, pattern)\n",
    "    return result\n",
    "    \n",
    "#text = \"En los E.U. U.S.A. esa postal vale $15.50... (feo) `hola` Acoso Escolar (Bullying) en San Juan de Pasto.... J.D.A.A.S. baby Santiago's clubc slsda-sdasd-ss D.I.A. A.C.E. dia\"\n",
    "\n",
    "#clean_text(text)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Cargamos Datos Originales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "resumenes_docentes = pd.read_excel(\"./Data/Resumenes.xlsx\",sheet_name = \"Proyectos Docentes\")\n",
    "resumenes_estudiantes = pd.read_excel(\"./Data/Resumenes.xlsx\",sheet_name=\"studiantiles y Trabajos de G\")\n",
    "\n",
    "#Eliminamos  Columnas\n",
    "resumenes_docentes.drop(columns=['No.'], inplace=True)\n",
    "resumenes_estudiantes.drop(columns=['No.'], inplace=True)\n",
    "\n",
    "#Eliminamos NAN\n",
    "resumenes_docentes.dropna(inplace=True)\n",
    "resumenes_estudiantes.dropna(inplace=True)\n",
    "\n",
    "#Asignamos index\n",
    "resumenes_docentes['index'] = [*range(1,len(resumenes_docentes)+1)]\n",
    "resumenes_docentes.set_index('index', inplace=True)\n",
    "\n",
    "resumenes_estudiantes['index'] = [*range(1,len(resumenes_estudiantes)+1)]\n",
    "resumenes_estudiantes.set_index('index', inplace=True)\n",
    "\n",
    "#Asignamos Columnas\n",
    "resumenes_docentes.columns = [\"codigo\", \"titulo\", \"resumen\", \"estado\", \"id_autor\", \"nombre_autor\", \n",
    "                     \"programa\", \"facultad\", \"convocatoria\", \"grupo_investigacion\", \"linea_investigacion\", \"palabras_clave\"]\n",
    "\n",
    "resumenes_estudiantes.columns = ['codigo', 'titulo', 'resumen', 'estado', 'id_autor', 'nombre_autor',\n",
    "       'programa', 'departamento', 'facultad', 'nombre_asesor', 'convocatoria', 'grupo_investigacion', 'linea_investigacion', 'palabras_clave']\n",
    "\n",
    "\n",
    "#Eliminamos registros no encontrados\n",
    "resumenes_docentes['palabras_clave'] = resumenes_docentes['palabras_clave'].apply(lambda row: row if (row != 'No se encontraron palabras clave registradas') else \" \")\n",
    "resumenes_estudiantes['palabras_clave'] = resumenes_estudiantes['palabras_clave'].apply(lambda row: row if (row != 'No se encontraron palabras clave registradas') else \" \")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Corpus agregado al DF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Agregamos Columna de Corpus palabras tokenizadas\n",
    "resumenes_docentes['corpus'] = resumenes_docentes.apply(lambda row: row['titulo']+' '+row['resumen']+' '+' '+row['palabras_clave']+' '+row['nombre_autor']+' '+row['programa']+' '+' '+row['facultad']+' '+row['grupo_investigacion']+' '+row['linea_investigacion'],axis=1)\n",
    "\n",
    "resumenes_estudiantes['corpus'] = resumenes_estudiantes.apply(lambda row: row['titulo']+' '+row['resumen']+' '+' '+row['palabras_clave']+' '+row['nombre_autor']+' '+row['nombre_asesor']+' '+row['programa']+' '+row['departamento']+' '+row['facultad']+' '+row['grupo_investigacion']+' '+row['linea_investigacion'],axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Palabras Tokenizadas y Limpias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "resumenes_docentes['palabras']=''\n",
    "for index, row in resumenes_docentes.iterrows():\n",
    "    tokens_corpus = clean_text(row['corpus'])\n",
    "    palabras = [palabra for palabra in tokens_corpus if not palabra in stopwords and len(palabra) > 3]\n",
    "    resumenes_docentes.at[index, 'palabras'] = palabras\n",
    "\n",
    "resumenes_estudiantes['palabras']=''\n",
    "for index, row in resumenes_estudiantes.iterrows():\n",
    "    tokens_corpus = clean_text(row['corpus'])\n",
    "    palabras = [palabra for palabra in tokens_corpus if not palabra in stopwords and len(palabra) > 3]\n",
    "    resumenes_estudiantes.at[index, 'palabras'] = palabras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vocabulario del Resumen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "resumenes_docentes['vocabulario'] = ''\n",
    "resumenes_docentes['vocabulario_corpus'] = ' '\n",
    "for index, row in resumenes_docentes.iterrows():\n",
    "    vocabulario = set(row['palabras'])\n",
    "    vocabulario_corpus = ' '.join([palabra for palabra in vocabulario])\n",
    "    resumenes_docentes.at[index, 'vocabulario'] = vocabulario\n",
    "    resumenes_docentes.at[index, 'vocabulario_corpus'] = vocabulario_corpus\n",
    "\n",
    "resumenes_estudiantes['vocabulario'] = ''\n",
    "resumenes_estudiantes['vocabulario_corpus'] = ''\n",
    "for index, row in resumenes_estudiantes.iterrows():\n",
    "    vocabulario = set(row['palabras'])\n",
    "    vocabulario_corpus = ' '.join([palabra for palabra in vocabulario])\n",
    "    resumenes_estudiantes.at[index, 'vocabulario'] = vocabulario\n",
    "    resumenes_estudiantes.at[index, 'vocabulario_corpus'] = vocabulario_corpus\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>codigo</th>\n",
       "      <th>titulo</th>\n",
       "      <th>resumen</th>\n",
       "      <th>estado</th>\n",
       "      <th>id_autor</th>\n",
       "      <th>nombre_autor</th>\n",
       "      <th>programa</th>\n",
       "      <th>facultad</th>\n",
       "      <th>convocatoria</th>\n",
       "      <th>grupo_investigacion</th>\n",
       "      <th>linea_investigacion</th>\n",
       "      <th>palabras_clave</th>\n",
       "      <th>corpus</th>\n",
       "      <th>palabras</th>\n",
       "      <th>vocabulario</th>\n",
       "      <th>vocabulario_corpus</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>index</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1464.0</td>\n",
       "      <td>\"Diagnóstico del impacto de las iniciativas em...</td>\n",
       "      <td>El emprendimiento es entre otras acepciones es...</td>\n",
       "      <td>Vencido</td>\n",
       "      <td>13515.0</td>\n",
       "      <td>Francisco Rafael Ayala</td>\n",
       "      <td>Diseño</td>\n",
       "      <td>Artes</td>\n",
       "      <td>Docente 2017</td>\n",
       "      <td>Currículo y Universidad</td>\n",
       "      <td>Curriculos pertinentes</td>\n",
       "      <td>Diagnóstico</td>\n",
       "      <td>\"Diagnóstico del impacto de las iniciativas em...</td>\n",
       "      <td>[diagnóstico, impacto, iniciativas, emprendedo...</td>\n",
       "      <td>{dispuesto, profesionales, identificar, papel,...</td>\n",
       "      <td>dispuesto profesionales identificar papel bene...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1367.0</td>\n",
       "      <td>Acoso Escolar (Bullying) en San Juan de Pasto....</td>\n",
       "      <td>A nivel mundial, uno de cada tres escolares ha...</td>\n",
       "      <td>Prorroga</td>\n",
       "      <td>11902.0</td>\n",
       "      <td>Harvey Mauricio Herrera Lopez</td>\n",
       "      <td>Psicología</td>\n",
       "      <td>Ciencias Humanas</td>\n",
       "      <td>Docente 2017</td>\n",
       "      <td>Psicología y Salud</td>\n",
       "      <td>Aspectos Psicosociales en Procesos de Salud</td>\n",
       "      <td>Acoso Escolar</td>\n",
       "      <td>Acoso Escolar (Bullying) en San Juan de Pasto....</td>\n",
       "      <td>[acoso, escolar, bullying, juan, pasto, modelo...</td>\n",
       "      <td>{ítem, mental, representa, bullying, modelos, ...</td>\n",
       "      <td>ítem mental representa bullying modelos empíri...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1343.0</td>\n",
       "      <td>ACTIVIDAD ANTIBACTERIAL DE POLIFENOLES DEL AGU...</td>\n",
       "      <td>El cáncer gástrico (CG) es la principal causa ...</td>\n",
       "      <td>Vencido</td>\n",
       "      <td>10081.0</td>\n",
       "      <td>Nelson Humberto Hurtado Gutierrez</td>\n",
       "      <td>Química</td>\n",
       "      <td>Ciencias Exactas y Naturales</td>\n",
       "      <td>Docente 2016</td>\n",
       "      <td>GRUPO DE INVESTIGACIÓN EN PRODUCTOS DE IMPORTA...</td>\n",
       "      <td>Modelado molecular</td>\n",
       "      <td>cancer gastrico</td>\n",
       "      <td>ACTIVIDAD ANTIBACTERIAL DE POLIFENOLES DEL AGU...</td>\n",
       "      <td>[actividad, antibacterial, polifenoles, aguaca...</td>\n",
       "      <td>{altas, frente, papel, dieta, preponderante, n...</td>\n",
       "      <td>altas frente papel dieta preponderante natural...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       codigo                                             titulo  \\\n",
       "index                                                              \n",
       "1      1464.0  \"Diagnóstico del impacto de las iniciativas em...   \n",
       "2      1367.0  Acoso Escolar (Bullying) en San Juan de Pasto....   \n",
       "3      1343.0  ACTIVIDAD ANTIBACTERIAL DE POLIFENOLES DEL AGU...   \n",
       "\n",
       "                                                 resumen    estado  id_autor  \\\n",
       "index                                                                          \n",
       "1      El emprendimiento es entre otras acepciones es...   Vencido   13515.0   \n",
       "2      A nivel mundial, uno de cada tres escolares ha...  Prorroga   11902.0   \n",
       "3      El cáncer gástrico (CG) es la principal causa ...   Vencido   10081.0   \n",
       "\n",
       "                            nombre_autor    programa  \\\n",
       "index                                                  \n",
       "1                 Francisco Rafael Ayala      Diseño   \n",
       "2          Harvey Mauricio Herrera Lopez  Psicología   \n",
       "3      Nelson Humberto Hurtado Gutierrez     Química   \n",
       "\n",
       "                           facultad  convocatoria  \\\n",
       "index                                               \n",
       "1                             Artes  Docente 2017   \n",
       "2                  Ciencias Humanas  Docente 2017   \n",
       "3      Ciencias Exactas y Naturales  Docente 2016   \n",
       "\n",
       "                                     grupo_investigacion  \\\n",
       "index                                                      \n",
       "1                                Currículo y Universidad   \n",
       "2                                     Psicología y Salud   \n",
       "3      GRUPO DE INVESTIGACIÓN EN PRODUCTOS DE IMPORTA...   \n",
       "\n",
       "                               linea_investigacion   palabras_clave  \\\n",
       "index                                                                 \n",
       "1                           Curriculos pertinentes      Diagnóstico   \n",
       "2      Aspectos Psicosociales en Procesos de Salud    Acoso Escolar   \n",
       "3                               Modelado molecular  cancer gastrico   \n",
       "\n",
       "                                                  corpus  \\\n",
       "index                                                      \n",
       "1      \"Diagnóstico del impacto de las iniciativas em...   \n",
       "2      Acoso Escolar (Bullying) en San Juan de Pasto....   \n",
       "3      ACTIVIDAD ANTIBACTERIAL DE POLIFENOLES DEL AGU...   \n",
       "\n",
       "                                                palabras  \\\n",
       "index                                                      \n",
       "1      [diagnóstico, impacto, iniciativas, emprendedo...   \n",
       "2      [acoso, escolar, bullying, juan, pasto, modelo...   \n",
       "3      [actividad, antibacterial, polifenoles, aguaca...   \n",
       "\n",
       "                                             vocabulario  \\\n",
       "index                                                      \n",
       "1      {dispuesto, profesionales, identificar, papel,...   \n",
       "2      {ítem, mental, representa, bullying, modelos, ...   \n",
       "3      {altas, frente, papel, dieta, preponderante, n...   \n",
       "\n",
       "                                      vocabulario_corpus  \n",
       "index                                                     \n",
       "1      dispuesto profesionales identificar papel bene...  \n",
       "2      ítem mental representa bullying modelos empíri...  \n",
       "3      altas frente papel dieta preponderante natural...  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Revisamos Datos\n",
    "resumenes_docentes.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>codigo</th>\n",
       "      <th>titulo</th>\n",
       "      <th>resumen</th>\n",
       "      <th>estado</th>\n",
       "      <th>id_autor</th>\n",
       "      <th>nombre_autor</th>\n",
       "      <th>programa</th>\n",
       "      <th>departamento</th>\n",
       "      <th>facultad</th>\n",
       "      <th>nombre_asesor</th>\n",
       "      <th>convocatoria</th>\n",
       "      <th>grupo_investigacion</th>\n",
       "      <th>linea_investigacion</th>\n",
       "      <th>palabras_clave</th>\n",
       "      <th>corpus</th>\n",
       "      <th>palabras</th>\n",
       "      <th>vocabulario</th>\n",
       "      <th>vocabulario_corpus</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>index</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>741.0</td>\n",
       "      <td>AISLAMIENTO, CARACTERIZACION, ESTABILIDAD Y AC...</td>\n",
       "      <td>El color es una de las cualidades sensoriales ...</td>\n",
       "      <td>Terminado</td>\n",
       "      <td>12324.0</td>\n",
       "      <td>Omaira Carolina Betancourt Ramos</td>\n",
       "      <td>Química</td>\n",
       "      <td>Química</td>\n",
       "      <td>Ciencias Exactas y Naturales</td>\n",
       "      <td>Nelson Humberto</td>\n",
       "      <td>Adicional de Trabajos de Grado 2013</td>\n",
       "      <td>GRUPO DE INVESTIGACIÓN EN PRODUCTOS DE IMPORTA...</td>\n",
       "      <td>Productos naturales</td>\n",
       "      <td></td>\n",
       "      <td>AISLAMIENTO, CARACTERIZACION, ESTABILIDAD Y AC...</td>\n",
       "      <td>[aislamiento, caracterizacion, estabilidad, ac...</td>\n",
       "      <td>{asocia, identificar, frente, picrylhydrazil, ...</td>\n",
       "      <td>asocia identificar frente picrylhydrazil añadi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>760.0</td>\n",
       "      <td>ANÁLISIS DE ALGORITMOS PARALELOS PARA LA TAREA...</td>\n",
       "      <td>La propuesta de la investigación se centra en ...</td>\n",
       "      <td>Cancelado</td>\n",
       "      <td>12479.0</td>\n",
       "      <td>Rosa Maria Zambrano Burbano</td>\n",
       "      <td>Ingeniería de Sistemas</td>\n",
       "      <td>Sistemas</td>\n",
       "      <td>Ingeniería</td>\n",
       "      <td>Manuel Ernesto</td>\n",
       "      <td>Adicional de Trabajos de Grado 2013</td>\n",
       "      <td>GRIAS</td>\n",
       "      <td>Deteccione de patrones con tecnicas de mineria...</td>\n",
       "      <td></td>\n",
       "      <td>ANÁLISIS DE ALGORITMOS PARALELOS PARA LA TAREA...</td>\n",
       "      <td>[análisis, algoritmos, paralelos, tarea, miner...</td>\n",
       "      <td>{identificar, sustraer, conoce, costos, razón,...</td>\n",
       "      <td>identificar sustraer conoce costos razón toma ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1412.0</td>\n",
       "      <td>ANÁLISIS DE FUNCIONALIDAD DE LA HERRAMIENTA DE...</td>\n",
       "      <td>Hoy en día se puede encontrar muchas opciones ...</td>\n",
       "      <td>Vencido</td>\n",
       "      <td>13872.0</td>\n",
       "      <td>Carlos Mario Coral Cabrera</td>\n",
       "      <td>Ingeniería de Sistemas</td>\n",
       "      <td>Sistemas</td>\n",
       "      <td>Ingeniería</td>\n",
       "      <td>Silvio Ricardo</td>\n",
       "      <td>Estudiantil 2017</td>\n",
       "      <td>GRIAS</td>\n",
       "      <td>Descubrimiento de conocimiento en bases de datos</td>\n",
       "      <td>Análisis de funcionalidad</td>\n",
       "      <td>ANÁLISIS DE FUNCIONALIDAD DE LA HERRAMIENTA DE...</td>\n",
       "      <td>[análisis, funcionalidad, herramienta, intelig...</td>\n",
       "      <td>{profesionales, libre, toma, presente, permite...</td>\n",
       "      <td>profesionales libre toma presente permite ayud...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       codigo                                             titulo  \\\n",
       "index                                                              \n",
       "1       741.0  AISLAMIENTO, CARACTERIZACION, ESTABILIDAD Y AC...   \n",
       "2       760.0  ANÁLISIS DE ALGORITMOS PARALELOS PARA LA TAREA...   \n",
       "3      1412.0  ANÁLISIS DE FUNCIONALIDAD DE LA HERRAMIENTA DE...   \n",
       "\n",
       "                                                 resumen     estado  id_autor  \\\n",
       "index                                                                           \n",
       "1      El color es una de las cualidades sensoriales ...  Terminado   12324.0   \n",
       "2      La propuesta de la investigación se centra en ...  Cancelado   12479.0   \n",
       "3      Hoy en día se puede encontrar muchas opciones ...    Vencido   13872.0   \n",
       "\n",
       "                           nombre_autor                programa departamento  \\\n",
       "index                                                                          \n",
       "1      Omaira Carolina Betancourt Ramos                 Química      Química   \n",
       "2           Rosa Maria Zambrano Burbano  Ingeniería de Sistemas     Sistemas   \n",
       "3            Carlos Mario Coral Cabrera  Ingeniería de Sistemas     Sistemas   \n",
       "\n",
       "                           facultad    nombre_asesor  \\\n",
       "index                                                  \n",
       "1      Ciencias Exactas y Naturales  Nelson Humberto   \n",
       "2                        Ingeniería   Manuel Ernesto   \n",
       "3                        Ingeniería   Silvio Ricardo   \n",
       "\n",
       "                              convocatoria  \\\n",
       "index                                        \n",
       "1      Adicional de Trabajos de Grado 2013   \n",
       "2      Adicional de Trabajos de Grado 2013   \n",
       "3                         Estudiantil 2017   \n",
       "\n",
       "                                     grupo_investigacion  \\\n",
       "index                                                      \n",
       "1      GRUPO DE INVESTIGACIÓN EN PRODUCTOS DE IMPORTA...   \n",
       "2                                                  GRIAS   \n",
       "3                                                  GRIAS   \n",
       "\n",
       "                                     linea_investigacion  \\\n",
       "index                                                      \n",
       "1                                    Productos naturales   \n",
       "2      Deteccione de patrones con tecnicas de mineria...   \n",
       "3       Descubrimiento de conocimiento en bases de datos   \n",
       "\n",
       "                  palabras_clave  \\\n",
       "index                              \n",
       "1                                  \n",
       "2                                  \n",
       "3      Análisis de funcionalidad   \n",
       "\n",
       "                                                  corpus  \\\n",
       "index                                                      \n",
       "1      AISLAMIENTO, CARACTERIZACION, ESTABILIDAD Y AC...   \n",
       "2      ANÁLISIS DE ALGORITMOS PARALELOS PARA LA TAREA...   \n",
       "3      ANÁLISIS DE FUNCIONALIDAD DE LA HERRAMIENTA DE...   \n",
       "\n",
       "                                                palabras  \\\n",
       "index                                                      \n",
       "1      [aislamiento, caracterizacion, estabilidad, ac...   \n",
       "2      [análisis, algoritmos, paralelos, tarea, miner...   \n",
       "3      [análisis, funcionalidad, herramienta, intelig...   \n",
       "\n",
       "                                             vocabulario  \\\n",
       "index                                                      \n",
       "1      {asocia, identificar, frente, picrylhydrazil, ...   \n",
       "2      {identificar, sustraer, conoce, costos, razón,...   \n",
       "3      {profesionales, libre, toma, presente, permite...   \n",
       "\n",
       "                                      vocabulario_corpus  \n",
       "index                                                     \n",
       "1      asocia identificar frente picrylhydrazil añadi...  \n",
       "2      identificar sustraer conoce costos razón toma ...  \n",
       "3      profesionales libre toma presente permite ayud...  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "resumenes_estudiantes.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experimental"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "resumenes_docentes.to_json(r'./Data/ResumenesDocentes.json')\n",
    "resumenes_estudiantes.to_json(r'./Data/ResumenesEstudiante.json')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Guardar CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "resumenes_docentes.to_csv(r'./Data/ResumenesDocentes.csv')\n",
    "resumenes_estudiantes.to_csv(r'./Data/ResumenesEstudiantes.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lemas Completo Resumen 1\n"
     ]
    }
   ],
   "source": [
    "json_resumen['lemas'] = ''\n",
    "for index, row in json_resumen.iterrows():\n",
    "    if( index > 1): break\n",
    "    vocabulario = row['vocabulario']\n",
    "    json_resumen.at[index, 'lemas'] = [lemmatizer(palabra) for palabra in vocabulario]\n",
    "    print(f'Lemas Completo Resumen {index}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Carga de datos de prueba limpios\n",
    "\n",
    "**ejecutar a partir de aqui para los LEMAS**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lematizar Palabras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cargar Datos ya procesados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import ast\n",
    "\n",
    "resumenes_docentes = pd.read_csv(\"./Data/ResumenesDocentes.csv\", index_col=0)\n",
    "resumenes_estudiantes = pd.read_csv(\"./Data/ResumenesEstudiantes.csv\", index_col=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>codigo</th>\n",
       "      <th>titulo</th>\n",
       "      <th>resumen</th>\n",
       "      <th>estado</th>\n",
       "      <th>id_autor</th>\n",
       "      <th>nombre_autor</th>\n",
       "      <th>programa</th>\n",
       "      <th>facultad</th>\n",
       "      <th>convocatoria</th>\n",
       "      <th>grupo_investigacion</th>\n",
       "      <th>linea_investigacion</th>\n",
       "      <th>palabras_clave</th>\n",
       "      <th>corpus</th>\n",
       "      <th>palabras</th>\n",
       "      <th>vocabulario</th>\n",
       "      <th>vocabulario_corpus</th>\n",
       "      <th>lemas_corpus</th>\n",
       "      <th>lemas</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>index</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1464.0</td>\n",
       "      <td>\"Diagnóstico del impacto de las iniciativas em...</td>\n",
       "      <td>El emprendimiento es entre otras acepciones es...</td>\n",
       "      <td>Vencido</td>\n",
       "      <td>13515.0</td>\n",
       "      <td>Francisco Rafael Ayala</td>\n",
       "      <td>Diseño</td>\n",
       "      <td>Artes</td>\n",
       "      <td>Docente 2017</td>\n",
       "      <td>Currículo y Universidad</td>\n",
       "      <td>Curriculos pertinentes</td>\n",
       "      <td>Diagnóstico</td>\n",
       "      <td>\"Diagnóstico del impacto de las iniciativas em...</td>\n",
       "      <td>['diagnóstico', 'impacto', 'iniciativas', 'emp...</td>\n",
       "      <td>{'dispuesto', 'profesionales', 'identificar', ...</td>\n",
       "      <td>dispuesto profesionales identificar papel bene...</td>\n",
       "      <td>disponer profesional identificar papel benefi...</td>\n",
       "      <td>[disponer, profesional, identificar, papel, be...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       codigo                                             titulo  \\\n",
       "index                                                              \n",
       "1      1464.0  \"Diagnóstico del impacto de las iniciativas em...   \n",
       "\n",
       "                                                 resumen   estado id_autor  \\\n",
       "index                                                                        \n",
       "1      El emprendimiento es entre otras acepciones es...  Vencido  13515.0   \n",
       "\n",
       "                 nombre_autor programa facultad  convocatoria  \\\n",
       "index                                                           \n",
       "1      Francisco Rafael Ayala   Diseño    Artes  Docente 2017   \n",
       "\n",
       "           grupo_investigacion     linea_investigacion palabras_clave  \\\n",
       "index                                                                   \n",
       "1      Currículo y Universidad  Curriculos pertinentes    Diagnóstico   \n",
       "\n",
       "                                                  corpus  \\\n",
       "index                                                      \n",
       "1      \"Diagnóstico del impacto de las iniciativas em...   \n",
       "\n",
       "                                                palabras  \\\n",
       "index                                                      \n",
       "1      ['diagnóstico', 'impacto', 'iniciativas', 'emp...   \n",
       "\n",
       "                                             vocabulario  \\\n",
       "index                                                      \n",
       "1      {'dispuesto', 'profesionales', 'identificar', ...   \n",
       "\n",
       "                                      vocabulario_corpus  \\\n",
       "index                                                      \n",
       "1      dispuesto profesionales identificar papel bene...   \n",
       "\n",
       "                                            lemas_corpus  \\\n",
       "index                                                      \n",
       "1       disponer profesional identificar papel benefi...   \n",
       "\n",
       "                                                   lemas  \n",
       "index                                                     \n",
       "1      [disponer, profesional, identificar, papel, be...  "
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resumenes_docentes.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Funcion de Lematizar una palabra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importar spacy para lemas\n",
    "import spacy\n",
    "nlp = spacy.load('es_core_news_sm')\n",
    "\n",
    "#Eliminacion de Tildes y dialisis\n",
    "normalizar = str.maketrans('áéíóúü','aeiouu')\n",
    "#Diccionario lemas\n",
    "diccionario_lemas = dict()\n",
    "\n",
    "def lemmatizer(text):\n",
    "  #Key Lema\n",
    "  #Value las Palabras Originales\n",
    "  lemas = ''\n",
    "  doc = nlp(text)\n",
    "  for word in doc:\n",
    "    #Agregamos el corpus de lemas\n",
    "    lemas = lemas + ' ' + word.lemma_\n",
    "    lemas = lemas.translate(normalizar)\n",
    "\n",
    "    #Eliminamos tildes de palabras\n",
    "    cleaned_lema = word.lemma_.translate(normalizar)\n",
    "    cleaned_word = word.text.translate(normalizar)\n",
    "\n",
    "    #Obtenemos Lista de palabras asociadas al lema\n",
    "    list_lemas = diccionario_lemas.get(cleaned_lema)\n",
    "\n",
    "    #Verificar si el Lema existe\n",
    "    if( list_lemas == None):\n",
    "      #Agregamos palabra original y lema\n",
    "      diccionario_lemas[cleaned_lema] = [ cleaned_word, cleaned_lema]\n",
    "    else:\n",
    "      #Revisamos si es una nueva palabra\n",
    "      if cleaned_word not in list_lemas:\n",
    "        diccionario_lemas[cleaned_lema].append(cleaned_word)\n",
    "\n",
    "    #print(' '.join([word.lema_ for word in doc]))\n",
    "  #print(lemas)\n",
    "  return lemas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Agregar Lemas a Docentes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lemas como corpus - DOCENTES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lemas Completo Resumen 1\n",
      "Lemas Completo Resumen 2\n",
      "Lemas Completo Resumen 3\n",
      "Lemas Completo Resumen 4\n",
      "Lemas Completo Resumen 5\n",
      "Lemas Completo Resumen 6\n",
      "Lemas Completo Resumen 7\n",
      "Lemas Completo Resumen 8\n",
      "Lemas Completo Resumen 9\n",
      "Lemas Completo Resumen 10\n",
      "Lemas Completo Resumen 11\n",
      "Lemas Completo Resumen 12\n",
      "Lemas Completo Resumen 13\n",
      "Lemas Completo Resumen 14\n",
      "Lemas Completo Resumen 15\n",
      "Lemas Completo Resumen 16\n",
      "Lemas Completo Resumen 17\n",
      "Lemas Completo Resumen 18\n",
      "Lemas Completo Resumen 19\n",
      "Lemas Completo Resumen 20\n",
      "Lemas Completo Resumen 21\n",
      "Lemas Completo Resumen 22\n",
      "Lemas Completo Resumen 23\n",
      "Lemas Completo Resumen 24\n",
      "Lemas Completo Resumen 25\n",
      "Lemas Completo Resumen 26\n",
      "Lemas Completo Resumen 27\n",
      "Lemas Completo Resumen 28\n",
      "Lemas Completo Resumen 29\n",
      "Lemas Completo Resumen 30\n",
      "Lemas Completo Resumen 31\n",
      "Lemas Completo Resumen 32\n",
      "Lemas Completo Resumen 33\n",
      "Lemas Completo Resumen 34\n",
      "Lemas Completo Resumen 35\n",
      "Lemas Completo Resumen 36\n",
      "Lemas Completo Resumen 37\n",
      "Lemas Completo Resumen 38\n",
      "Lemas Completo Resumen 39\n",
      "Lemas Completo Resumen 40\n",
      "Lemas Completo Resumen 41\n",
      "Lemas Completo Resumen 42\n",
      "Lemas Completo Resumen 43\n",
      "Lemas Completo Resumen 44\n",
      "Lemas Completo Resumen 45\n",
      "Lemas Completo Resumen 46\n",
      "Lemas Completo Resumen 47\n",
      "Lemas Completo Resumen 48\n",
      "Lemas Completo Resumen 49\n",
      "Lemas Completo Resumen 50\n",
      "Lemas Completo Resumen 51\n",
      "Lemas Completo Resumen 52\n",
      "Lemas Completo Resumen 53\n",
      "Lemas Completo Resumen 54\n",
      "Lemas Completo Resumen 55\n",
      "Lemas Completo Resumen 56\n",
      "Lemas Completo Resumen 57\n",
      "Lemas Completo Resumen 58\n",
      "Lemas Completo Resumen 59\n",
      "Lemas Completo Resumen 60\n",
      "Lemas Completo Resumen 61\n",
      "Lemas Completo Resumen 62\n",
      "Lemas Completo Resumen 63\n",
      "Lemas Completo Resumen 64\n",
      "Lemas Completo Resumen 65\n",
      "Lemas Completo Resumen 66\n",
      "Lemas Completo Resumen 67\n",
      "Lemas Completo Resumen 68\n",
      "Lemas Completo Resumen 69\n",
      "Lemas Completo Resumen 70\n",
      "Lemas Completo Resumen 71\n",
      "Lemas Completo Resumen 72\n",
      "Lemas Completo Resumen 73\n",
      "Lemas Completo Resumen 74\n",
      "Lemas Completo Resumen 75\n",
      "Lemas Completo Resumen 76\n",
      "Lemas Completo Resumen 77\n",
      "Lemas Completo Resumen 78\n",
      "Lemas Completo Resumen 79\n",
      "Lemas Completo Resumen 80\n",
      "Lemas Completo Resumen 81\n",
      "Lemas Completo Resumen 82\n",
      "Lemas Completo Resumen 83\n",
      "Lemas Completo Resumen 84\n",
      "Lemas Completo Resumen 85\n",
      "Lemas Completo Resumen 86\n",
      "Lemas Completo Resumen 87\n",
      "Lemas Completo Resumen 88\n",
      "Lemas Completo Resumen 89\n",
      "Lemas Completo Resumen 90\n",
      "Lemas Completo Resumen 91\n",
      "Lemas Completo Resumen 92\n",
      "Lemas Completo Resumen 93\n",
      "Lemas Completo Resumen 94\n",
      "Lemas Completo Resumen 95\n",
      "Lemas Completo Resumen 96\n",
      "Lemas Completo Resumen 97\n",
      "Lemas Completo Resumen 98\n",
      "Lemas Completo Resumen 99\n",
      "Lemas Completo Resumen 100\n",
      "Lemas Completo Resumen 101\n",
      "Lemas Completo Resumen 102\n",
      "Lemas Completo Resumen 103\n",
      "Lemas Completo Resumen 104\n",
      "Lemas Completo Resumen 105\n",
      "Lemas Completo Resumen 106\n",
      "Lemas Completo Resumen 107\n",
      "Lemas Completo Resumen 108\n",
      "Lemas Completo Resumen 109\n",
      "Lemas Completo Resumen 110\n",
      "Lemas Completo Resumen 111\n",
      "Lemas Completo Resumen 112\n",
      "Lemas Completo Resumen 113\n",
      "Lemas Completo Resumen 114\n",
      "Lemas Completo Resumen 115\n",
      "Lemas Completo Resumen 116\n",
      "Lemas Completo Resumen 117\n",
      "Lemas Completo Resumen 118\n",
      "Lemas Completo Resumen 119\n",
      "Lemas Completo Resumen 120\n",
      "Lemas Completo Resumen 121\n",
      "Lemas Completo Resumen 122\n",
      "Lemas Completo Resumen 123\n",
      "Lemas Completo Resumen 124\n",
      "Lemas Completo Resumen 125\n",
      "Lemas Completo Resumen 126\n",
      "Lemas Completo Resumen 127\n",
      "Lemas Completo Resumen 128\n",
      "Lemas Completo Resumen 129\n",
      "Lemas Completo Resumen 130\n",
      "Lemas Completo Resumen 131\n",
      "Lemas Completo Resumen 132\n",
      "Lemas Completo Resumen 133\n",
      "Lemas Completo Resumen 134\n",
      "Lemas Completo Resumen 135\n",
      "Lemas Completo Resumen 136\n",
      "Lemas Completo Resumen 137\n",
      "Lemas Completo Resumen 138\n",
      "Lemas Completo Resumen 139\n",
      "Lemas Completo Resumen 140\n",
      "Lemas Completo Resumen 141\n",
      "Lemas Completo Resumen 142\n",
      "Lemas Completo Resumen 143\n",
      "Lemas Completo Resumen 144\n",
      "Lemas Completo Resumen 145\n",
      "Lemas Completo Resumen 146\n",
      "Lemas Completo Resumen 147\n",
      "Lemas Completo Resumen 148\n",
      "Lemas Completo Resumen 149\n",
      "Lemas Completo Resumen 150\n",
      "Lemas Completo Resumen 151\n",
      "Lemas Completo Resumen 152\n",
      "Lemas Completo Resumen 153\n",
      "Lemas Completo Resumen 154\n",
      "Lemas Completo Resumen 155\n",
      "Lemas Completo Resumen 156\n",
      "Lemas Completo Resumen 157\n",
      "Lemas Completo Resumen 158\n",
      "Lemas Completo Resumen 159\n",
      "Lemas Completo Resumen 160\n",
      "Lemas Completo Resumen 161\n",
      "Lemas Completo Resumen 162\n",
      "Lemas Completo Resumen 163\n",
      "Lemas Completo Resumen 164\n",
      "Lemas Completo Resumen 165\n",
      "Lemas Completo Resumen 166\n",
      "Lemas Completo Resumen 167\n",
      "Lemas Completo Resumen 168\n",
      "Lemas Completo Resumen 169\n",
      "Lemas Completo Resumen 170\n",
      "Lemas Completo Resumen 171\n",
      "Lemas Completo Resumen 172\n",
      "Lemas Completo Resumen 173\n",
      "Lemas Completo Resumen 174\n",
      "Lemas Completo Resumen 175\n",
      "Lemas Completo Resumen 176\n",
      "Lemas Completo Resumen 177\n",
      "Lemas Completo Resumen 178\n",
      "Lemas Completo Resumen 179\n",
      "Lemas Completo Resumen 180\n",
      "Lemas Completo Resumen 181\n",
      "Lemas Completo Resumen 182\n",
      "Lemas Completo Resumen 183\n",
      "Lemas Completo Resumen 184\n",
      "Lemas Completo Resumen 185\n",
      "Lemas Completo Resumen 186\n",
      "Lemas Completo Resumen 187\n",
      "Lemas Completo Resumen 188\n",
      "Lemas Completo Resumen 189\n",
      "Lemas Completo Resumen 190\n",
      "Lemas Completo Resumen 191\n",
      "Lemas Completo Resumen 192\n",
      "Lemas Completo Resumen 193\n",
      "Lemas Completo Resumen 194\n",
      "Lemas Completo Resumen 195\n",
      "Lemas Completo Resumen 196\n",
      "Lemas Completo Resumen 197\n",
      "Lemas Completo Resumen 198\n",
      "Lemas Completo Resumen 199\n",
      "Lemas Completo Resumen 200\n",
      "Lemas Completo Resumen 201\n",
      "Lemas Completo Resumen 202\n",
      "Lemas Completo Resumen 203\n",
      "Lemas Completo Resumen 204\n",
      "Lemas Completo Resumen 205\n",
      "Lemas Completo Resumen 206\n",
      "Lemas Completo Resumen 207\n",
      "Lemas Completo Resumen 208\n",
      "Lemas Completo Resumen 209\n",
      "Lemas Completo Resumen 210\n",
      "Lemas Completo Resumen 211\n",
      "Lemas Completo Resumen 212\n",
      "Lemas Completo Resumen 213\n",
      "Lemas Completo Resumen 214\n",
      "Lemas Completo Resumen 215\n",
      "Lemas Completo Resumen 216\n",
      "Lemas Completo Resumen 217\n",
      "Lemas Completo Resumen 218\n",
      "Lemas Completo Resumen 219\n",
      "Lemas Completo Resumen 220\n",
      "Lemas Completo Resumen 221\n",
      "Lemas Completo Resumen 222\n",
      "Lemas Completo Resumen 223\n",
      "Lemas Completo Resumen 224\n",
      "Lemas Completo Resumen 225\n",
      "Lemas Completo Resumen 226\n",
      "Lemas Completo Resumen 227\n",
      "Lemas Completo Resumen 228\n",
      "Lemas Completo Resumen 229\n",
      "Lemas Completo Resumen 230\n",
      "Lemas Completo Resumen 231\n",
      "Lemas Completo Resumen 232\n",
      "Lemas Completo Resumen 233\n",
      "Lemas Completo Resumen 234\n",
      "Lemas Completo Resumen 235\n",
      "Lemas Completo Resumen 236\n",
      "Lemas Completo Resumen 237\n",
      "Lemas Completo Resumen 238\n",
      "Lemas Completo Resumen 239\n",
      "Lemas Completo Resumen 240\n",
      "Lemas Completo Resumen 241\n",
      "Lemas Completo Resumen 242\n",
      "Lemas Completo Resumen 243\n",
      "Lemas Completo Resumen 244\n",
      "Lemas Completo Resumen 245\n",
      "Lemas Completo Resumen 246\n",
      "Lemas Completo Resumen 247\n",
      "Lemas Completo Resumen 248\n",
      "Lemas Completo Resumen 249\n",
      "Lemas Completo Resumen 250\n",
      "Lemas Completo Resumen 251\n",
      "Lemas Completo Resumen 252\n",
      "Lemas Completo Resumen 253\n",
      "Lemas Completo Resumen 254\n",
      "Lemas Completo Resumen 255\n",
      "Lemas Completo Resumen 256\n",
      "Lemas Completo Resumen 257\n",
      "Lemas Completo Resumen 258\n",
      "Lemas Completo Resumen 259\n",
      "Lemas Completo Resumen 260\n",
      "Lemas Completo Resumen 261\n",
      "Lemas Completo Resumen 262\n",
      "Lemas Completo Resumen 263\n",
      "Lemas Completo Resumen 264\n",
      "Lemas Completo Resumen 265\n",
      "Lemas Completo Resumen 266\n",
      "Lemas Completo Resumen 267\n",
      "Lemas Completo Resumen 268\n",
      "Lemas Completo Resumen 269\n",
      "Lemas Completo Resumen 270\n",
      "Lemas Completo Resumen 271\n",
      "Lemas Completo Resumen 272\n",
      "Lemas Completo Resumen 273\n",
      "Lemas Completo Resumen 274\n",
      "Lemas Completo Resumen 275\n",
      "Lemas Completo Resumen 276\n",
      "Lemas Completo Resumen 277\n",
      "Lemas Completo Resumen 278\n",
      "Lemas Completo Resumen 279\n",
      "Lemas Completo Resumen 280\n",
      "Lemas Completo Resumen 281\n",
      "Lemas Completo Resumen 282\n",
      "Lemas Completo Resumen 283\n",
      "Lemas Completo Resumen 284\n",
      "Lemas Completo Resumen 285\n",
      "Lemas Completo Resumen 286\n",
      "Lemas Completo Resumen 287\n",
      "Lemas Completo Resumen 288\n",
      "Lemas Completo Resumen 289\n",
      "Lemas Completo Resumen 290\n",
      "Lemas Completo Resumen 291\n",
      "Lemas Completo Resumen 292\n",
      "Lemas Completo Resumen 293\n",
      "Lemas Completo Resumen 294\n",
      "Lemas Completo Resumen 295\n",
      "Lemas Completo Resumen 296\n",
      "Lemas Completo Resumen 297\n",
      "Lemas Completo Resumen 298\n",
      "Lemas Completo Resumen 299\n",
      "Lemas Completo Resumen 300\n",
      "Lemas Completo Resumen 301\n",
      "Lemas Completo Resumen 302\n",
      "Lemas Completo Resumen 303\n",
      "Lemas Completo Resumen 304\n",
      "Lemas Completo Resumen 305\n",
      "Lemas Completo Resumen 306\n",
      "Lemas Completo Resumen 307\n",
      "Lemas Completo Resumen 308\n"
     ]
    }
   ],
   "source": [
    "resumenes_docentes['lemas_corpus'] = ''\n",
    "resumenes_docentes['lemas'] = ''\n",
    "for index, row in resumenes_docentes.iterrows():\n",
    "    #if( index > 1): break\n",
    "    vocabulario = ast.literal_eval(row['vocabulario'])\n",
    "    lemas_corpus = lemmatizer(row['vocabulario_corpus'])\n",
    "    #lemas_corpus = lemas_corpus.replace(' .', '.') # espacios de abreviaturas\n",
    "\n",
    "    lemas = list(lemas_corpus.split())\n",
    "    resumenes_docentes.at[index, 'lemas_corpus'] = lemas_corpus\n",
    "    resumenes_docentes.at[index, 'lemas'] = lemas    \n",
    "    print(f'Lemas Completo Resumen {index}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lemas como corpus - ESTUDIANTES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lemas Completo Resumen 1\n",
      "Lemas Completo Resumen 2\n",
      "Lemas Completo Resumen 3\n",
      "Lemas Completo Resumen 4\n",
      "Lemas Completo Resumen 5\n",
      "Lemas Completo Resumen 6\n",
      "Lemas Completo Resumen 7\n",
      "Lemas Completo Resumen 8\n",
      "Lemas Completo Resumen 9\n",
      "Lemas Completo Resumen 10\n",
      "Lemas Completo Resumen 11\n",
      "Lemas Completo Resumen 12\n",
      "Lemas Completo Resumen 13\n",
      "Lemas Completo Resumen 14\n",
      "Lemas Completo Resumen 15\n",
      "Lemas Completo Resumen 16\n",
      "Lemas Completo Resumen 17\n",
      "Lemas Completo Resumen 18\n",
      "Lemas Completo Resumen 19\n",
      "Lemas Completo Resumen 20\n",
      "Lemas Completo Resumen 21\n",
      "Lemas Completo Resumen 22\n",
      "Lemas Completo Resumen 23\n",
      "Lemas Completo Resumen 24\n",
      "Lemas Completo Resumen 25\n",
      "Lemas Completo Resumen 26\n",
      "Lemas Completo Resumen 27\n",
      "Lemas Completo Resumen 28\n",
      "Lemas Completo Resumen 29\n",
      "Lemas Completo Resumen 30\n",
      "Lemas Completo Resumen 31\n",
      "Lemas Completo Resumen 32\n",
      "Lemas Completo Resumen 33\n",
      "Lemas Completo Resumen 34\n",
      "Lemas Completo Resumen 35\n",
      "Lemas Completo Resumen 36\n",
      "Lemas Completo Resumen 37\n",
      "Lemas Completo Resumen 38\n",
      "Lemas Completo Resumen 39\n",
      "Lemas Completo Resumen 40\n",
      "Lemas Completo Resumen 41\n",
      "Lemas Completo Resumen 42\n",
      "Lemas Completo Resumen 43\n",
      "Lemas Completo Resumen 44\n",
      "Lemas Completo Resumen 45\n",
      "Lemas Completo Resumen 46\n",
      "Lemas Completo Resumen 47\n",
      "Lemas Completo Resumen 48\n",
      "Lemas Completo Resumen 49\n",
      "Lemas Completo Resumen 50\n",
      "Lemas Completo Resumen 51\n",
      "Lemas Completo Resumen 52\n",
      "Lemas Completo Resumen 53\n",
      "Lemas Completo Resumen 54\n",
      "Lemas Completo Resumen 55\n",
      "Lemas Completo Resumen 56\n",
      "Lemas Completo Resumen 57\n",
      "Lemas Completo Resumen 58\n",
      "Lemas Completo Resumen 59\n",
      "Lemas Completo Resumen 60\n",
      "Lemas Completo Resumen 61\n",
      "Lemas Completo Resumen 62\n",
      "Lemas Completo Resumen 63\n",
      "Lemas Completo Resumen 64\n",
      "Lemas Completo Resumen 65\n",
      "Lemas Completo Resumen 66\n",
      "Lemas Completo Resumen 67\n",
      "Lemas Completo Resumen 68\n",
      "Lemas Completo Resumen 69\n",
      "Lemas Completo Resumen 70\n",
      "Lemas Completo Resumen 71\n",
      "Lemas Completo Resumen 72\n",
      "Lemas Completo Resumen 73\n",
      "Lemas Completo Resumen 74\n",
      "Lemas Completo Resumen 75\n",
      "Lemas Completo Resumen 76\n",
      "Lemas Completo Resumen 77\n",
      "Lemas Completo Resumen 78\n",
      "Lemas Completo Resumen 79\n",
      "Lemas Completo Resumen 80\n",
      "Lemas Completo Resumen 81\n",
      "Lemas Completo Resumen 82\n",
      "Lemas Completo Resumen 83\n",
      "Lemas Completo Resumen 84\n",
      "Lemas Completo Resumen 85\n",
      "Lemas Completo Resumen 86\n",
      "Lemas Completo Resumen 87\n",
      "Lemas Completo Resumen 88\n",
      "Lemas Completo Resumen 89\n",
      "Lemas Completo Resumen 90\n",
      "Lemas Completo Resumen 91\n",
      "Lemas Completo Resumen 92\n",
      "Lemas Completo Resumen 93\n",
      "Lemas Completo Resumen 94\n",
      "Lemas Completo Resumen 95\n",
      "Lemas Completo Resumen 96\n",
      "Lemas Completo Resumen 97\n",
      "Lemas Completo Resumen 98\n",
      "Lemas Completo Resumen 99\n",
      "Lemas Completo Resumen 100\n",
      "Lemas Completo Resumen 101\n",
      "Lemas Completo Resumen 102\n",
      "Lemas Completo Resumen 103\n",
      "Lemas Completo Resumen 104\n",
      "Lemas Completo Resumen 105\n",
      "Lemas Completo Resumen 106\n",
      "Lemas Completo Resumen 107\n",
      "Lemas Completo Resumen 108\n",
      "Lemas Completo Resumen 109\n",
      "Lemas Completo Resumen 110\n",
      "Lemas Completo Resumen 111\n",
      "Lemas Completo Resumen 112\n",
      "Lemas Completo Resumen 113\n",
      "Lemas Completo Resumen 114\n",
      "Lemas Completo Resumen 115\n",
      "Lemas Completo Resumen 116\n",
      "Lemas Completo Resumen 117\n",
      "Lemas Completo Resumen 118\n",
      "Lemas Completo Resumen 119\n",
      "Lemas Completo Resumen 120\n",
      "Lemas Completo Resumen 121\n",
      "Lemas Completo Resumen 122\n",
      "Lemas Completo Resumen 123\n",
      "Lemas Completo Resumen 124\n",
      "Lemas Completo Resumen 125\n",
      "Lemas Completo Resumen 126\n",
      "Lemas Completo Resumen 127\n",
      "Lemas Completo Resumen 128\n",
      "Lemas Completo Resumen 129\n",
      "Lemas Completo Resumen 130\n",
      "Lemas Completo Resumen 131\n",
      "Lemas Completo Resumen 132\n",
      "Lemas Completo Resumen 133\n",
      "Lemas Completo Resumen 134\n",
      "Lemas Completo Resumen 135\n",
      "Lemas Completo Resumen 136\n",
      "Lemas Completo Resumen 137\n",
      "Lemas Completo Resumen 138\n",
      "Lemas Completo Resumen 139\n",
      "Lemas Completo Resumen 140\n",
      "Lemas Completo Resumen 141\n",
      "Lemas Completo Resumen 142\n",
      "Lemas Completo Resumen 143\n"
     ]
    }
   ],
   "source": [
    "resumenes_estudiantes['lemas_corpus'] = ''\n",
    "resumenes_estudiantes['lemas'] = ''\n",
    "for index, row in resumenes_estudiantes.iterrows():\n",
    "    #if( index > 1): break\n",
    "    vocabulario = ast.literal_eval(row['vocabulario'])\n",
    "    lemas_corpus = lemmatizer(row['vocabulario_corpus'])\n",
    "    lemas = list(lemas_corpus.split())\n",
    "    resumenes_estudiantes.at[index, 'lemas_corpus'] = lemas_corpus\n",
    "    resumenes_estudiantes.at[index, 'lemas'] = lemas    \n",
    "    print(f'Lemas Completo Resumen {index}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Guardamos diccionario de Lemas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Guardamos diccionario como JSON\n",
    "import json\n",
    "\n",
    "with open('./Data/diccionario-lemas.json', 'w') as f:\n",
    "    json.dump(diccionario_lemas, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'disponer': ['dispuesto', 'disponer'],\n",
       " 'profesional': ['profesionales', 'profesional'],\n",
       " 'identificar': ['identificar', 'identificar'],\n",
       " 'papel': ['papel', 'papel'],\n",
       " 'beneficio': ['beneficios', 'beneficio'],\n",
       " 'flexible': ['flexible', 'flexible'],\n",
       " 'pretender': ['pretende', 'pretender'],\n",
       " 'conveniente': ['conveniente', 'conveniente'],\n",
       " 'permitir': ['permitira', 'permitir'],\n",
       " 'aporte': ['aportes', 'aporte'],\n",
       " 'basico': ['basica', 'basico'],\n",
       " 'relacionar': ['relaciones', 'relacionar'],\n",
       " 'formador': ['formadores', 'formador'],\n",
       " 'estudio': ['estudios', 'estudio'],\n",
       " 'gradar': ['grado', 'gradar'],\n",
       " 'nivel': ['nivel', 'nivel'],\n",
       " 'complejidad': ['complejidad', 'complejidad'],\n",
       " 'grupo': ['grupos', 'grupo'],\n",
       " 'continuo': ['continuo', 'continuo'],\n",
       " 'fomentar': ['fomentar', 'fomentar', 'fomento'],\n",
       " 'tecnologico': ['tecnologicos', 'tecnologico'],\n",
       " 'publico': ['publica', 'publico'],\n",
       " 'beneficiar': ['beneficio', 'beneficiar'],\n",
       " 'colectivo': ['colectivo', 'colectivo'],\n",
       " 'creativo': ['creativo', 'creativo'],\n",
       " 'afrontar': ['afrontar', 'afrontar'],\n",
       " 'emprendedor': ['emprendedoras', 'emprendedor'],\n",
       " 'promover': ['promovida', 'promover'],\n",
       " 'experiencia': ['experiencias', 'experiencia'],\n",
       " 'academico': ['academico', 'academico'],\n",
       " 'proponer': ['propuesta', 'proponer'],\n",
       " 'cambiar': ['cambio', 'cambiar'],\n",
       " 'universidad': ['universidad', 'universidad'],\n",
       " 'individual': ['individual', 'individual'],\n",
       " 'evolucionar': ['evoluciones', 'evolucionar'],\n",
       " 'procesar': ['proceso', 'procesar'],\n",
       " 'ayala': ['ayala', 'ayala'],\n",
       " 'complejo': ['complejas', 'complejo'],\n",
       " 'interesar': ['intereses', 'interesar'],\n",
       " 'tipificar': ['tipificar', 'tipificar'],\n",
       " 'expectativa': ['expectativas', 'expectativa'],\n",
       " 'escuchar': ['escuchar', 'escuchar'],\n",
       " 'importancia': ['importancia', 'importancia'],\n",
       " 'modalidad': ['modalidades', 'modalidad'],\n",
       " 'participar': ['participar', 'participar'],\n",
       " 'asociar': ['asociado', 'asociar'],\n",
       " 'dinamico': ['dinamica', 'dinamico'],\n",
       " 'egresar': ['egresados', 'egresar'],\n",
       " 'sostenible': ['sostenibles', 'sostenible'],\n",
       " 'vital': ['vital', 'vital'],\n",
       " 'plantear': ['plantea', 'plantear'],\n",
       " 'particular': ['particular', 'particular'],\n",
       " 'catalogar': ['catalogan', 'catalogar'],\n",
       " 'individuo': ['individuo', 'individuo', 'individuos'],\n",
       " 'aportar': ['aporta', 'aportar'],\n",
       " 'estimulante': ['estimulantes', 'estimulante'],\n",
       " 'concienciar': ['conciencia', 'concienciar'],\n",
       " 'principio': ['principios', 'principio'],\n",
       " 'desarrollo': ['desarrollos', 'desarrollo'],\n",
       " 'humano': ['humana', 'humano'],\n",
       " 'conjuntar': ['conjunto', 'conjuntar'],\n",
       " 'capaz': ['capaz', 'capaz'],\n",
       " 'capacidad': ['capacidad', 'capacidad', 'capacidades'],\n",
       " 'social': ['sociales', 'social'],\n",
       " 'industriar': ['industria', 'industriar'],\n",
       " 'extremar': ['extremo', 'extremar'],\n",
       " 'crecimiento': ['crecimiento', 'crecimiento'],\n",
       " 'innovador': ['innovador', 'innovador'],\n",
       " 'asumir': ['asumir', 'asumir'],\n",
       " 'diseñar': ['diseño', 'diseñar'],\n",
       " 'estrategico': ['estrategicos', 'estrategico'],\n",
       " 'creacion': ['creacion', 'creacion'],\n",
       " 'impacto': ['impactos', 'impacto'],\n",
       " 'establecer': ['establece', 'establecer'],\n",
       " 'caso': ['casos', 'caso'],\n",
       " 'cambio': ['cambios', 'cambio'],\n",
       " 'primordial': ['primordiales', 'primordial'],\n",
       " 'iniciativo': ['iniciativas', 'iniciativo'],\n",
       " 'marcar': ['marco', 'marcar'],\n",
       " 'crear': ['crear', 'crear'],\n",
       " 'fenomeno': ['fenomeno', 'fenomeno'],\n",
       " 'turismo': ['turismo', 'turismo'],\n",
       " 'indagar': ['indagar', 'indagar', 'indaga'],\n",
       " 'laboral': ['laboral', 'laboral'],\n",
       " 'fortalecimiento': ['fortalecimiento', 'fortalecimiento'],\n",
       " 'institucion': ['instituciones', 'institucion'],\n",
       " 'perfilar': ['perfiles', 'perfilar'],\n",
       " 'entorno': ['entornos', 'entorno'],\n",
       " 'genesis': ['genesis', 'genesis'],\n",
       " 'implicar': ['implica', 'implicar'],\n",
       " 'proceso': ['procesos', 'proceso'],\n",
       " 'equipar': ['equipo', 'equipar'],\n",
       " 'sistema': ['sistema', 'sistema'],\n",
       " 'programar': ['programa', 'programar'],\n",
       " 'privar': ['privadas', 'privar'],\n",
       " 'entidad': ['entidades', 'entidad'],\n",
       " 'apoyar': ['apoyo', 'apoyar'],\n",
       " 'personar': ['personas', 'personar'],\n",
       " 'derecho': ['derecho', 'derecho'],\n",
       " 'empresa': ['empresas', 'empresa'],\n",
       " 'desarrollar': ['desarrollo', 'desarrollar'],\n",
       " 'colombiano': ['colombiano', 'colombiano'],\n",
       " 'curriculo': ['curriculo', 'curriculo'],\n",
       " 'rafael': ['rafael', 'rafael'],\n",
       " 'extincion': ['extincion', 'extincion'],\n",
       " 'latente': ['latente', 'latente'],\n",
       " 'formar': ['formas', 'formar'],\n",
       " 'local': ['local', 'local'],\n",
       " 'objetivo': ['objetivos', 'objetivo'],\n",
       " 'buscar': ['buscando', 'buscar'],\n",
       " 'actor': ['actores', 'actor'],\n",
       " 'proposito': ['propositos', 'proposito'],\n",
       " 'solucionar': ['soluciones', 'solucionar'],\n",
       " 'incertidumbre': ['incertidumbre', 'incertidumbre'],\n",
       " 'reconocimiento': ['reconocimiento', 'reconocimiento'],\n",
       " 'mejoramiento': ['mejoramiento', 'mejoramiento'],\n",
       " 'humanar': ['humano', 'humanar'],\n",
       " 'estructurar': ['estructurar', 'estructurar'],\n",
       " 'sociedad': ['sociedad', 'sociedad'],\n",
       " 'industrial': ['industrial', 'industrial'],\n",
       " 'promocion': ['promocion', 'promocion'],\n",
       " 'diagnostico': ['diagnostico', 'diagnostico'],\n",
       " 'economico': ['economicos', 'economico'],\n",
       " 'enfrentar': ['enfrentado', 'enfrentar'],\n",
       " 'orientar': ['orientado', 'orientar'],\n",
       " 'investigacion': ['investigacion', 'investigacion'],\n",
       " 'casar': ['caso', 'casar'],\n",
       " 'formacion': ['formacion', 'formacion'],\n",
       " 'impactar': ['impacto', 'impactar'],\n",
       " 'plan': ['plan', 'plan'],\n",
       " 'emprendimiento': ['emprendimiento', 'emprendimiento'],\n",
       " 'contribuir': ['contribuir', 'contribuir'],\n",
       " 'necesidad': ['necesidad', 'necesidad', 'necesidades'],\n",
       " 'actual': ['actuales', 'actual'],\n",
       " 'riesgo': ['riesgos', 'riesgo'],\n",
       " 'francisco': ['francisco', 'francisco'],\n",
       " 'consolidacion': ['consolidacion', 'consolidacion'],\n",
       " 'contexto': ['contexto', 'contexto'],\n",
       " 'arte': ['artes', 'arte'],\n",
       " 'curriculos': ['curriculos', 'curriculos'],\n",
       " 'alianza': ['alianzas', 'alianza'],\n",
       " 'integral': ['integral', 'integral'],\n",
       " 'ministerio': ['ministerio', 'ministerio'],\n",
       " 'nariño': ['nariño', 'nariño'],\n",
       " 'asociativo': ['asociativo', 'asociativo'],\n",
       " 'alcanzar': ['alcances', 'alcanzar'],\n",
       " 'pertinente': ['pertinentes', 'pertinente'],\n",
       " 'ejercer': ['ejercer', 'ejercer'],\n",
       " 'generar': ['generadas', 'generar'],\n",
       " 'describir': ['describe', 'describir'],\n",
       " 'condicionar': ['condiciones', 'condicionar'],\n",
       " 'acepcion': ['acepciones', 'acepcion'],\n",
       " 'comerciar': ['comercio', 'comerciar'],\n",
       " 'facilitar': ['facilitar', 'facilitar'],\n",
       " 'ecosistema': ['ecosistema', 'ecosistema'],\n",
       " 'responsabilidad': ['responsabilidad', 'responsabilidad'],\n",
       " 'situacion': ['situaciones', 'situacion'],\n",
       " 'mejorar': ['mejores', 'mejorar'],\n",
       " 'integrante': ['integrantes', 'integrante'],\n",
       " 'descubrir': ['descubrir', 'descubrir'],\n",
       " 'cultura': ['cultura', 'cultura'],\n",
       " 'politico': ['politicos', 'politico'],\n",
       " 'proyectar': ['proyecto', 'proyectar'],\n",
       " 'manifiesto': ['manifiesta', 'manifiesto']}"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Lectura de lemas \n",
    "import json\n",
    "with open('./Data/otro.json', 'r') as f:\n",
    "    diccionario_lemas = json.loads(f.read())\n",
    "diccionario_lemas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9208"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(diccionario_lemas)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Agregar Lemas a Estudiantes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "lemas = [ lemmatizer(palabra) for palabra in vocabulario]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
